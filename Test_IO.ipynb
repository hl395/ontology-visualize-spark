{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'spark://128.235.40.174:7077'),\n",
       " ('spark.driver.port', '41147'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '10G'),\n",
       " ('spark.driver.extraClassPath', '/home/hao/pixiedust/data/libs/*'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.jars', 'file:/home/hao/pixiedust/bin/cloudant-spark-v2.0.0-185.jar'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', '128.235.40.174'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'app-20171130102519-0008'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.executor.memory', '4G')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809619\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- PARENT_CLASS_IRI: string (nullable = true)\n",
      "\n",
      "711444\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      "\n",
      "1258\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "343737\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "381471\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "2.7048428058624268 seconds\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      "\n",
      "29.385645151138306 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"PARENT_CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_class_hier= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/ONT_CLASS_HIERARCHY.csv\")\n",
    "    \n",
    "    \n",
    "print(df_class_hier.count())\n",
    "df_class_hier.printSchema()\n",
    "df_class_hier=df_class_hier.distinct()\n",
    "# df_class_hier.createGlobalTempView(\"class_hier\")\n",
    "df_class_hier.createOrReplaceTempView(\"class_hier\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"CLASS_LABEL\", StringType())\n",
    "])\n",
    "\n",
    "df_class_labels= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/ONT_CLASS_LABELS.csv\")\n",
    "\n",
    "    \n",
    "print(df_class_labels.count())\n",
    "df_class_labels.printSchema()\n",
    "df_class_labels=df_class_labels.distinct()\n",
    "# df_class_labels.createGlobalTempView(\"class_labels\")\n",
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"AREA_NAME\", StringType()),\n",
    "    StructField(\"AREA_LEVEL\", IntegerType())\n",
    "])\n",
    "\n",
    "df_tax_areas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS.csv\")\n",
    "\n",
    "print(df_tax_areas.count())\n",
    "df_tax_areas.printSchema()\n",
    "df_tax_areas=df_tax_areas.distinct()\n",
    "# df_tax_areas.createGlobalTempView(\"tax_areas\")\n",
    "df_tax_areas.createOrReplaceTempView(\"tax_areas\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_concepts= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS_CONCEPTS.csv\")\n",
    "\n",
    "print(df_tax_areas_concepts.count())\n",
    "df_tax_areas_concepts.printSchema()\n",
    "df_tax_areas_concepts=df_tax_areas_concepts.distinct()\n",
    "# df_tax_areas_concepts.createGlobalTempView(\"tax_areas_concepts\")\n",
    "df_tax_areas_concepts.createOrReplaceTempView(\"tax_areas_concepts\")\n",
    "\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"PAREA_ROOT_IRI\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_pareas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS_PAREAS.csv\")\n",
    "\n",
    "print(df_tax_areas_pareas.count())\n",
    "df_tax_areas_pareas.printSchema()\n",
    "df_tax_areas_pareas=df_tax_areas_pareas.distinct()\n",
    "# df_tax_areas_pareas.createGlobalTempView(\"tax_areas_pareas\")\n",
    "df_tax_areas_pareas.createOrReplaceTempView(\"tax_areas_pareas\")\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")\n",
    "\n",
    "# df_class_labels\n",
    "# df_class_hier\n",
    "# df_tax_areas\n",
    "# df_tax_areas_concepts\n",
    "# df_tax_areas_pareas\n",
    "\n",
    "# return unioned df_union\n",
    "\n",
    "df_hier = df_class_hier.rdd.map(lambda x : (x[1], x[2], x[0])).distinct().toDF(['src', 'dst', 'ont'])\n",
    "\n",
    "# find which ont it belongs to \n",
    "\n",
    "# find which area it belongs to\n",
    "result = df_class_labels.join(df_tax_areas_concepts, ['CLASS_IRI', 'ONT_NAME'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "# find which area level it belongs to\n",
    "result = result.join(df_tax_areas, ['ONT_NAME', 'TAX_TYPE', 'AREA_ID'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "# find which parea it belongs to \n",
    "result = result.join(df_tax_areas_pareas, ['CLASS_IRI', 'ONT_NAME', 'TAX_TYPE'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "df_union = result.rdd.map(lambda x: (x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7])).distinct().toDF(['id', 'ont','type', 'area_id','label', 'area_name', 'area_level', 'parea_root_id'])\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with standalone (Spark 2.2)",
   "language": "python",
   "name": "pythonwithoutsparkload"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
