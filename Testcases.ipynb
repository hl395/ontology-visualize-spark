{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 pyspark-shell'\n",
    "\n",
    "# import pixiedust\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# from pixiedust.packageManager import PackageManager\n",
    "# pkg=PackageManager()\n",
    "# pkg.installPackage(\"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "# pkg.printAllPackages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.jars.packages',\n",
       "  'graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2,com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2'),\n",
       " ('spark.files',\n",
       "  'file:/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,file:/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.driver.port', '46683'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.memory', '1G'),\n",
       " ('spark.master', 'spark://192.168.1.15:7077'),\n",
       " ('spark.driver.extraClassPath', '/home/hao/pixiedust/data/libs/*'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.app.name', 'sparkPlot_testing2'),\n",
       " ('spark.driver.host', '192.168.1.15'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.id', 'app-20171202171316-0015'),\n",
       " ('spark.jars',\n",
       "  'file:/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,file:/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.submit.deployMode', 'client')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"spark://192.168.1.15:7077\") \\\n",
    "   .appName(\"sparkPlot_testing2\") \\\n",
    "   .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "   .config(\"spark.cores.max\",\"4\")\\\n",
    "   .config(\"spark.executor.cores\",\"1\")\\\n",
    "   .config(\"spark.executor.memory\", \"1G\") \\\n",
    "   .config('spark.driver.extraClassPath', '/home/hao/pixiedust/data/libs/*')\\\n",
    "   .config(\"spark.jars.packages\", \"graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2,com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "#.config('spark.jars', 'file:/home/hao/pixiedust/bin/cloudant-spark-v2.0.0-185.jar')\\\n",
    "#    .config(\"spark.serializer\",\"org.apache.spark.serializer.JavaSerializer\")\\    \n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlContext=SQLContext(sc)\n",
    "\n",
    "spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809619\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- PARENT_CLASS_IRI: string (nullable = true)\n",
      "\n",
      "711444\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      "\n",
      "1258\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "343737\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "381471\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "6.976520538330078 seconds\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      "\n",
      "50.80666494369507 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"PARENT_CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_class_hier= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_HIERARCHY.csv\")\n",
    "    \n",
    "    \n",
    "print(df_class_hier.count())\n",
    "df_class_hier.printSchema()\n",
    "df_class_hier=df_class_hier.distinct()\n",
    "# df_class_hier.createGlobalTempView(\"class_hier\")\n",
    "df_class_hier.createOrReplaceTempView(\"class_hier\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"CLASS_LABEL\", StringType())\n",
    "])\n",
    "\n",
    "df_class_labels= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_LABELS.csv\")\n",
    "\n",
    "    \n",
    "print(df_class_labels.count())\n",
    "df_class_labels.printSchema()\n",
    "df_class_labels=df_class_labels.distinct()\n",
    "# df_class_labels.createGlobalTempView(\"class_labels\")\n",
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"AREA_NAME\", StringType()),\n",
    "    StructField(\"AREA_LEVEL\", IntegerType())\n",
    "])\n",
    "\n",
    "df_tax_areas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS.csv\")\n",
    "\n",
    "print(df_tax_areas.count())\n",
    "df_tax_areas.printSchema()\n",
    "df_tax_areas=df_tax_areas.distinct()\n",
    "# df_tax_areas.createGlobalTempView(\"tax_areas\")\n",
    "df_tax_areas.createOrReplaceTempView(\"tax_areas\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_concepts= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_CONCEPTS.csv\")\n",
    "\n",
    "print(df_tax_areas_concepts.count())\n",
    "df_tax_areas_concepts.printSchema()\n",
    "df_tax_areas_concepts=df_tax_areas_concepts.distinct()\n",
    "# df_tax_areas_concepts.createGlobalTempView(\"tax_areas_concepts\")\n",
    "df_tax_areas_concepts.createOrReplaceTempView(\"tax_areas_concepts\")\n",
    "\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"PAREA_ROOT_IRI\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_pareas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_PAREAS.csv\")\n",
    "\n",
    "print(df_tax_areas_pareas.count())\n",
    "df_tax_areas_pareas.printSchema()\n",
    "df_tax_areas_pareas=df_tax_areas_pareas.distinct()\n",
    "# df_tax_areas_pareas.createGlobalTempView(\"tax_areas_pareas\")\n",
    "df_tax_areas_pareas.createOrReplaceTempView(\"tax_areas_pareas\")\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")\n",
    "\n",
    "# df_class_labels\n",
    "# df_class_hier\n",
    "# df_tax_areas\n",
    "# df_tax_areas_concepts\n",
    "# df_tax_areas_pareas\n",
    "\n",
    "# return unioned df_union\n",
    "\n",
    "df_hier = df_class_hier.rdd.map(lambda x : (x[1], x[2], x[0])).distinct().toDF(['src', 'dst', 'ont'])\n",
    "\n",
    "# find which ont it belongs to \n",
    "\n",
    "# find which area it belongs to\n",
    "result = df_class_labels.join(df_tax_areas_concepts, ['CLASS_IRI', 'ONT_NAME'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "# find which area level it belongs to\n",
    "result = result.join(df_tax_areas, ['ONT_NAME', 'TAX_TYPE', 'AREA_ID'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "# find which parea it belongs to \n",
    "result = result.join(df_tax_areas_pareas, ['CLASS_IRI', 'ONT_NAME', 'TAX_TYPE'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "df_union = result.rdd.map(lambda x: (x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7])).distinct().toDF(['id', 'ont','type', 'area_id','label', 'area_name', 'area_level', 'parea_root_id'])\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "|id                                                                                       |inDegree|\n",
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "|http://ncicb.nci.nih.gov/xml/owl/evs/thesaurus.owl#stage_iv_diffuse_large_b-cell_lymphoma|3       |\n",
      "|http://edamontology.org/data_3736                                                        |1       |\n",
      "|http://purl.obolibrary.org/obo/chebi_64517                                               |6       |\n",
      "|http://purl.obolibrary.org/obo/dermo_0003319                                             |12      |\n",
      "|http://purl.obolibrary.org/obo/dron_00000024                                             |59      |\n",
      "|http://childhealthservicemodels.eu/asthma#mocha-asthma_000082                            |15      |\n",
      "|http://purl.obolibrary.org/obo/chebi_26106                                               |5       |\n",
      "|http://www.ebi.ac.uk/ancestro/ancestro_0002                                              |22      |\n",
      "|http://purl.obolibrary.org/obo/chebi_64371                                               |2       |\n",
      "|http://purl.obolibrary.org/obo/chebi_23014                                               |10      |\n",
      "|http://www.orpha.net/ordo/orphanet_183557                                                |6       |\n",
      "|http://purl.obolibrary.org/obo/eco_0001046                                               |1       |\n",
      "|http://semanticscience.org/resource/sio_000783                                           |1       |\n",
      "|http://purl.obolibrary.org/obo/chebi_29067                                               |60      |\n",
      "|http://purl.obolibrary.org/obo/dron_00030442                                             |26      |\n",
      "|http://www.ifomis.org/bfo/1.1/snap#role                                                  |25      |\n",
      "|http://purl.obolibrary.org/obo/dron_00026876                                             |1       |\n",
      "|http://purl.obolibrary.org/obo/dron_00059951                                             |1       |\n",
      "|http://purl.obolibrary.org/obo/dron_00059992                                             |12      |\n",
      "|http://clininf.eu/ckdo#proteinuria_estimation                                            |3       |\n",
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "381574\n",
      "809295\n",
      "1692\n",
      "181470\n"
     ]
    }
   ],
   "source": [
    "from graphframes import *\n",
    "g = GraphFrame(df_union, df_hier)\n",
    "g.inDegrees.show(20, False)\n",
    "\n",
    "print(g.vertices.count())\n",
    "print(g.edges.count())\n",
    "\n",
    "v2 = g.vertices.filter(\"area_name = 'has part, is conjugate base of' and parea_root_id = 'http://purl.obolibrary.org/obo/chebi_29067'\")\n",
    "# v2 = g.vertices.filter(\"ont = 'chebi.obo'\")\n",
    "e2 = g.edges.filter(\"ont = 'chebi.obo'\")\n",
    "g2 = GraphFrame(v2, e2)\n",
    "print(g2.vertices.count())\n",
    "print(g2.edges.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692\n",
      "2155\n"
     ]
    }
   ],
   "source": [
    "def removeEdgesNotInVertices(g):\n",
    "    e = g.edges\n",
    "    v = g.vertices\n",
    "    vert = v.select('id').rdd.flatMap(lambda x: x).collect()\n",
    "    e2= e.filter((e.src.isin(vert)==True) & (e.dst.isin(vert)==True))\n",
    "    return GraphFrame(v, e2)\n",
    "    \n",
    "    \n",
    "    \n",
    "g2 = removeEdgesNotInVertices(g2)\n",
    "print(g2.vertices.count())\n",
    "print(g2.edges.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.813148975372314 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "results = g2.pageRank(resetProbability=0.15, maxIter=3)\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank until convergence to tolerance \"tol\".\n",
    "results = g2.pageRank(resetProbability=0.15, tol=0.1)\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank personalized for vertex \"a\"\n",
    "a = 'http://purl.obolibrary.org/obo/chebi_35693'\n",
    "results = g2.pageRank(resetProbability=0.15, maxIter=3, sourceId=a)\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "display(results.edges.select(\"src\", \"dst\", \"weight\").orderBy(desc(\"weight\")))\n",
    "display(results.vertices.select(\"id\",\"pagerank\").orderBy(desc(\"pagerank\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.328782081604004 seconds\n",
      "+--------------------+--------------------+\n",
      "|                  id|           distances|\n",
      "+--------------------+--------------------+\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|Map(http://purl.o...|\n",
      "|http://purl.oboli...|               Map()|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------------------------------+----+\n",
      "|id                                         |dist|\n",
      "+-------------------------------------------+----+\n",
      "|http://purl.obolibrary.org/obo/chebi_82903 |3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78072 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_58757 |3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_59203 |1   |\n",
      "|http://purl.obolibrary.org/obo/chebi_77216 |3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78091 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_133292|2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_33161 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_88020 |3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_131876|3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_133900|2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78066 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_133134|4   |\n",
      "|http://purl.obolibrary.org/obo/chebi_131862|3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_67260 |3   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78020 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_133451|4   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78052 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_78086 |2   |\n",
      "|http://purl.obolibrary.org/obo/chebi_136528|3   |\n",
      "+-------------------------------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = 'http://purl.obolibrary.org/obo/chebi_28868'\n",
    "# b = 'http://purl.obolibrary.org/obo/chebi_33549'\n",
    "results = g2.shortestPaths(landmarks=[a])\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")\n",
    "\n",
    "results.select(\"id\", \"distances\").show()\n",
    "# results.show(20, False)\n",
    "\n",
    "df = results.select(\"id\", \"distances\").withColumn('dist', results.distances.getItem(a)).drop(\"distances\")\n",
    "\n",
    "# df.printSchema()\n",
    "df.na.drop().show(20, False)\n",
    "# df.filter(df.testing !=\"null\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
