{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 pyspark-shell'\n",
    "\n",
    "# import pixiedust\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# from pixiedust.packageManager import PackageManager\n",
    "# pkg=PackageManager()\n",
    "# pkg.installPackage(\"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "# pkg.printAllPackages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'spark://128.235.40.174:7077'),\n",
       " ('spark.jars.packages',\n",
       "  'graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2,com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2'),\n",
       " ('spark.files',\n",
       "  'file:/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,file:/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.port', '37697'),\n",
       " ('spark.executor.memory', '1G'),\n",
       " ('spark.driver.extraClassPath', '/home/hao/pixiedust/data/libs/*'),\n",
       " ('spark.executor.cores', '4'),\n",
       " ('spark.cores.max', '4'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.app.name', 'sparkPlot_testing2'),\n",
       " ('spark.jars',\n",
       "  'file:/home/hao/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar,file:/home/hao/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar,file:/home/hao/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', '128.235.40.174'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'app-20171207120202-0045'),\n",
       " ('spark.submit.deployMode', 'client')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"spark://128.235.40.174:7077\") \\\n",
    "   .appName(\"sparkPlot_testing2\") \\\n",
    "   .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "   .config(\"spark.cores.max\",\"4\")\\\n",
    "   .config(\"spark.executor.cores\",\"4\")\\\n",
    "   .config(\"spark.executor.memory\", \"1G\") \\\n",
    "   .config('spark.driver.extraClassPath', '/home/hao/pixiedust/data/libs/*')\\\n",
    "   .config(\"spark.jars.packages\", \"graphframes:graphframes:0.5.0-spark2.1-s_2.11,com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2,com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "#.config('spark.jars', 'file:/home/hao/pixiedust/bin/cloudant-spark-v2.0.0-185.jar')\\\n",
    "#    .config(\"spark.serializer\",\"org.apache.spark.serializer.JavaSerializer\")\\    \n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlContext=SQLContext(sc)\n",
    "\n",
    "spark.sparkContext.getConf().getAll()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809619\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- PARENT_CLASS_IRI: string (nullable = true)\n",
      "\n",
      "711444\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      "\n",
      "1258\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "343737\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "381471\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n",
      "6.088229417800903 seconds\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      "\n",
      "43.59633111953735 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"PARENT_CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_class_hier= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/ONT_CLASS_HIERARCHY.csv\")\n",
    "    \n",
    "    \n",
    "print(df_class_hier.count())\n",
    "df_class_hier.printSchema()\n",
    "df_class_hier=df_class_hier.distinct()\n",
    "# df_class_hier.createGlobalTempView(\"class_hier\")\n",
    "df_class_hier.createOrReplaceTempView(\"class_hier\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"CLASS_LABEL\", StringType())\n",
    "])\n",
    "\n",
    "df_class_labels= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/ONT_CLASS_LABELS.csv\")\n",
    "\n",
    "    \n",
    "print(df_class_labels.count())\n",
    "df_class_labels.printSchema()\n",
    "df_class_labels=df_class_labels.distinct()\n",
    "# df_class_labels.createGlobalTempView(\"class_labels\")\n",
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"AREA_NAME\", StringType()),\n",
    "    StructField(\"AREA_LEVEL\", IntegerType())\n",
    "])\n",
    "\n",
    "df_tax_areas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS.csv\")\n",
    "\n",
    "print(df_tax_areas.count())\n",
    "df_tax_areas.printSchema()\n",
    "df_tax_areas=df_tax_areas.distinct()\n",
    "# df_tax_areas.createGlobalTempView(\"tax_areas\")\n",
    "df_tax_areas.createOrReplaceTempView(\"tax_areas\")\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_concepts= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS_CONCEPTS.csv\")\n",
    "\n",
    "print(df_tax_areas_concepts.count())\n",
    "df_tax_areas_concepts.printSchema()\n",
    "df_tax_areas_concepts=df_tax_areas_concepts.distinct()\n",
    "# df_tax_areas_concepts.createGlobalTempView(\"tax_areas_concepts\")\n",
    "df_tax_areas_concepts.createOrReplaceTempView(\"tax_areas_concepts\")\n",
    "\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"PAREA_ROOT_IRI\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_pareas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://128.235.40.174:9000/TAX_AREAS_PAREAS.csv\")\n",
    "\n",
    "print(df_tax_areas_pareas.count())\n",
    "df_tax_areas_pareas.printSchema()\n",
    "df_tax_areas_pareas=df_tax_areas_pareas.distinct()\n",
    "# df_tax_areas_pareas.createGlobalTempView(\"tax_areas_pareas\")\n",
    "df_tax_areas_pareas.createOrReplaceTempView(\"tax_areas_pareas\")\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")\n",
    "\n",
    "# df_class_labels\n",
    "# df_class_hier\n",
    "# df_tax_areas\n",
    "# df_tax_areas_concepts\n",
    "# df_tax_areas_pareas\n",
    "\n",
    "# return unioned df_union\n",
    "\n",
    "df_hier = df_class_hier.rdd.map(lambda x : (x[1], x[2], x[0])).distinct().toDF(['src', 'dst', 'ont'])\n",
    "\n",
    "# find which ont it belongs to \n",
    "\n",
    "# find which area it belongs to\n",
    "result = df_class_labels.join(df_tax_areas_concepts, ['CLASS_IRI', 'ONT_NAME'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "# find which area level it belongs to\n",
    "result = result.join(df_tax_areas, ['ONT_NAME', 'TAX_TYPE', 'AREA_ID'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "# find which parea it belongs to \n",
    "result = result.join(df_tax_areas_pareas, ['CLASS_IRI', 'ONT_NAME', 'TAX_TYPE'])\n",
    "# result.show(20 ,False)\n",
    "result.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "df_union = result.rdd.map(lambda x: (x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7])).distinct().toDF(['id', 'ont','type', 'area_id','label', 'area_name', 'area_level', 'parea_root_id'])\n",
    "\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "|id                                                                                       |inDegree|\n",
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "|http://purl.obolibrary.org/obo/dron_00027408                                             |1       |\n",
      "|http://semanticscience.org/resource/sio_010075                                           |4       |\n",
      "|http://purl.obolibrary.org/obo/ddo.owl#ddo_0003553                                       |6       |\n",
      "|http://mouse.brain-map.org/atlas/index.html#spvo                                         |5       |\n",
      "|http://purl.obolibrary.org/obo/chebi_18000                                               |85      |\n",
      "|http://semanticscience.org/resource/sio_000507                                           |6       |\n",
      "|http://purl.obolibrary.org/obo/dron_00032093                                             |1       |\n",
      "|http://ncicb.nci.nih.gov/xml/owl/evs/thesaurus.owl#cystic_neoplasm                       |3       |\n",
      "|http://purl.obolibrary.org/obo/chebi_38670                                               |56      |\n",
      "|http://purl.obolibrary.org/obo/chebi_47836                                               |2       |\n",
      "|http://purl.obolibrary.org/obo/dron_00023640                                             |28      |\n",
      "|http://purl.obolibrary.org/obo/chebi_24480                                               |1       |\n",
      "|http://purl.obolibrary.org/obo/bto_0003578                                               |2       |\n",
      "|http://cbo.biocomplexity.indiana.edu/svn/cbo/trunk/cbo_1_0.owl#systemwall                |3       |\n",
      "|http://edamontology.org/data_3736                                                        |1       |\n",
      "|http://purl.obolibrary.org/obo/chebi_64371                                               |2       |\n",
      "|http://childhealthservicemodels.eu/asthma#mocha-asthma_000082                            |15      |\n",
      "|http://purl.obolibrary.org/obo/chebi_64517                                               |6       |\n",
      "|http://purl.obolibrary.org/obo/dermo_0003319                                             |12      |\n",
      "|http://ncicb.nci.nih.gov/xml/owl/evs/thesaurus.owl#stage_iv_diffuse_large_b-cell_lymphoma|3       |\n",
      "+-----------------------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "381574\n",
      "809295\n",
      "1692\n",
      "181470\n"
     ]
    }
   ],
   "source": [
    "from graphframes import *\n",
    "g = GraphFrame(df_union, df_hier)\n",
    "g.inDegrees.show(20, False)\n",
    "\n",
    "print(g.vertices.count())\n",
    "print(g.edges.count())\n",
    "\n",
    "v2 = g.vertices.filter(\"area_name = 'has part, is conjugate base of' and parea_root_id = 'http://purl.obolibrary.org/obo/chebi_29067'\")\n",
    "# v2 = g.vertices.filter(\"ont = 'chebi.obo'\")\n",
    "e2 = g.edges.filter(\"ont = 'chebi.obo'\")\n",
    "g2 = GraphFrame(v2, e2)\n",
    "print(g2.vertices.count())\n",
    "print(g2.edges.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692\n",
      "2155\n"
     ]
    }
   ],
   "source": [
    "def removeEdgesNotInVertices(g):\n",
    "    e = g.edges\n",
    "    v = g.vertices\n",
    "    vert = v.select('id').rdd.flatMap(lambda x: x).collect()\n",
    "    e2= e.filter((e.src.isin(vert)==True) & (e.dst.isin(vert)==True))\n",
    "    return GraphFrame(v, e2)\n",
    "    \n",
    "    \n",
    "    \n",
    "g2 = removeEdgesNotInVertices(g2)\n",
    "print(g2.vertices.count())\n",
    "print(g2.edges.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174.38950157165527 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "results = g2.pageRank(resetProbability=0.15, maxIter=3)\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank until convergence to tolerance \"tol\".\n",
    "results = g2.pageRank(resetProbability=0.15, tol=0.1)\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Run PageRank personalized for vertex \"a\"\n",
    "a = 'http://purl.obolibrary.org/obo/chebi_35693'\n",
    "results = g2.pageRank(resetProbability=0.15, maxIter=3, sourceId=a)\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------+\n",
      "|id                                        |pagerank          |\n",
      "+------------------------------------------+------------------+\n",
      "|http://purl.obolibrary.org/obo/chebi_29067|421.7861132505724 |\n",
      "|http://purl.obolibrary.org/obo/chebi_35757|226.11055278398302|\n",
      "|http://purl.obolibrary.org/obo/chebi_28868|139.84188039349706|\n",
      "|http://purl.obolibrary.org/obo/chebi_2580 |62.663873499206915|\n",
      "|http://purl.obolibrary.org/obo/chebi_35693|38.53558061527573 |\n",
      "|http://purl.obolibrary.org/obo/chebi_28965|32.96684316050481 |\n",
      "|http://purl.obolibrary.org/obo/chebi_37022|27.244086476327887|\n",
      "|http://purl.obolibrary.org/obo/chebi_36059|26.522308176159665|\n",
      "|http://purl.obolibrary.org/obo/chebi_35903|23.36826080469135 |\n",
      "|http://purl.obolibrary.org/obo/chebi_38716|22.811322072197612|\n",
      "|http://purl.obolibrary.org/obo/chebi_33558|21.90735267091553 |\n",
      "|http://purl.obolibrary.org/obo/chebi_62937|20.984363736100594|\n",
      "|http://purl.obolibrary.org/obo/chebi_33721|17.507731645265068|\n",
      "|http://purl.obolibrary.org/obo/chebi_76567|16.698036742769926|\n",
      "|http://purl.obolibrary.org/obo/chebi_22299|15.302072300943399|\n",
      "|http://purl.obolibrary.org/obo/chebi_35902|14.962840074150265|\n",
      "|http://purl.obolibrary.org/obo/chebi_57560|14.645746757688057|\n",
      "|http://purl.obolibrary.org/obo/chebi_22718|11.296272596052784|\n",
      "|http://purl.obolibrary.org/obo/chebi_59835|9.682904921269932 |\n",
      "|http://purl.obolibrary.org/obo/chebi_33549|8.293872427883626 |\n",
      "+------------------------------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.vertices.select(\"id\",\"pagerank\").orderBy(desc(\"pagerank\")).show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "dataframe"
     }
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[src: string, dst: string, weight: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, pagerank: double]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pixiedust\n",
    "display(results.edges.select(\"src\", \"dst\", \"weight\").orderBy(desc(\"weight\")))\n",
    "display(results.vertices.select(\"id\",\"pagerank\").orderBy(desc(\"pagerank\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "a = 'http://purl.obolibrary.org/obo/chebi_28868'\n",
    "# b = 'http://purl.obolibrary.org/obo/chebi_33549'\n",
    "results = g2.shortestPaths(landmarks=[a])\n",
    "\n",
    "print(time.time() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.select(\"id\", \"distances\").show()\n",
    "# results.show(20, False)\n",
    "\n",
    "df = results.select(\"id\", \"distances\").withColumn('dist', results.distances.getItem(a)).drop(\"distances\")\n",
    "\n",
    "# df.printSchema()\n",
    "df.na.drop().show(20, False)\n",
    "# df.filter(df.testing !=\"null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
