{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "\n",
    "if sc.version.startswith('1.6.'):  # Spark 1.6\n",
    "    pixiedust.installPackage(\"graphframes:graphframes:0.5.0-spark1.6-s_2.11\")\n",
    "elif sc.version.startswith('2.'):  # Spark 2.1, 2.0\n",
    "    pixiedust.installPackage(\"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "\n",
    "\n",
    "pixiedust.installPackage(\"com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2\")\n",
    "pixiedust.installPackage(\"com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 pyspark-shell'\n",
    "\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"sparkPlot\") \\\n",
    "   .config(\"spark.executor.memory\", \"2gb\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "# spark.conf.set(\"spark.jars.packages\", \"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809619\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- PARENT_CLASS_IRI: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"PARENT_CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_class_hier= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_HIERARCHY.csv\")\n",
    "    \n",
    "    \n",
    "print(df_class_hier.count())\n",
    "df_class_hier.printSchema()\n",
    "df_class_hier=df_class_hier.distinct()\n",
    "df_class_hier.createGlobalTempView(\"class_hier\")\n",
    "\n",
    "# iri = \"http://purl.obolibrary.org/obo/iao_0000030\"\n",
    "# print(spark.sql(\"SELECT * from class_hier where CLASS_IRI = '\" + iri +\"'\").collect())\n",
    "# print(df_class_hier.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711444\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\"Temporary table 'class_labels' already exists;\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o727.createGlobalTempView.\n: org.apache.spark.sql.catalyst.analysis.TempTableAlreadyExistsException: Temporary table 'class_labels' already exists;\n\tat org.apache.spark.sql.catalyst.catalog.GlobalTempViewManager.create(GlobalTempViewManager.scala:61)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createGlobalTempView(SessionCatalog.scala:484)\n\tat org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:148)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:67)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:182)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:67)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2872)\n\tat org.apache.spark.sql.Dataset.createGlobalTempView(Dataset.scala:2658)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-33982d0654f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdf_class_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_class_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_class_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_class_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class_labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcreateGlobalTempView\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"Temporary table 'class_labels' already exists;\""
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"CLASS_LABEL\", StringType())\n",
    "])\n",
    "\n",
    "df_class_labels= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_LABELS.csv\")\n",
    "\n",
    "    \n",
    "print(df_class_labels.count())\n",
    "df_class_labels.printSchema()\n",
    "df_class_labels=df_class_labels.distinct()\n",
    "df_class_labels.createGlobalTempView(\"class_labels\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- AREA_NAME: string (nullable = true)\n",
      " |-- AREA_LEVEL: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\"Temporary table 'tax_areas' already exists;\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o794.createGlobalTempView.\n: org.apache.spark.sql.catalyst.analysis.TempTableAlreadyExistsException: Temporary table 'tax_areas' already exists;\n\tat org.apache.spark.sql.catalyst.catalog.GlobalTempViewManager.create(GlobalTempViewManager.scala:61)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createGlobalTempView(SessionCatalog.scala:484)\n\tat org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:148)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:67)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:182)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:67)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2872)\n\tat org.apache.spark.sql.Dataset.createGlobalTempView(Dataset.scala:2658)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d3232728b2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_tax_areas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_tax_areas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_tax_areas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_tax_areas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tax_areas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcreateGlobalTempView\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"Temporary table 'tax_areas' already exists;\""
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"AREA_NAME\", StringType()),\n",
    "    StructField(\"AREA_LEVEL\", IntegerType())\n",
    "])\n",
    "\n",
    "df_tax_areas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS.csv\")\n",
    "\n",
    "print(df_tax_areas.count())\n",
    "df_tax_areas.printSchema()\n",
    "df_tax_areas=df_tax_areas.distinct()\n",
    "df_tax_areas.createGlobalTempView(\"tax_areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343737\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- AREA_ID: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_concepts= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_CONCEPTS.csv\")\n",
    "\n",
    "print(df_tax_areas_concepts.count())\n",
    "df_tax_areas_concepts.printSchema()\n",
    "df_tax_areas_concepts=df_tax_areas_concepts.distinct()\n",
    "df_tax_areas_concepts.createGlobalTempView(\"tax_areas_concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381471\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- TAX_TYPE: string (nullable = true)\n",
      " |-- PAREA_ROOT_IRI: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "\"Temporary table 'tax_areas_pareas' already exists;\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o861.createGlobalTempView.\n: org.apache.spark.sql.catalyst.analysis.TempTableAlreadyExistsException: Temporary table 'tax_areas_pareas' already exists;\n\tat org.apache.spark.sql.catalyst.catalog.GlobalTempViewManager.create(GlobalTempViewManager.scala:61)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createGlobalTempView(SessionCatalog.scala:484)\n\tat org.apache.spark.sql.execution.command.CreateViewCommand.run(views.scala:148)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:67)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:182)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:67)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2872)\n\tat org.apache.spark.sql.Dataset.createGlobalTempView(Dataset.scala:2658)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0c88b5341765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdf_tax_areas_pareas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf_tax_areas_pareas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_tax_areas_pareas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_tax_areas_pareas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tax_areas_pareas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcreateGlobalTempView\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateGlobalTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"Temporary table 'tax_areas_pareas' already exists;\""
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"PAREA_ROOT_IRI\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_pareas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_PAREAS.csv\")\n",
    "\n",
    "print(df_tax_areas_pareas.count())\n",
    "df_tax_areas_pareas.printSchema()\n",
    "df_tax_areas_pareas=df_tax_areas_pareas.distinct()\n",
    "df_tax_areas_pareas.createGlobalTempView(\"tax_areas_pareas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|   ONT_NAME|\n",
      "+-----------+\n",
      "|chembio.owl|\n",
      "+-----------+\n",
      "\n",
      "+-----------+--------------+--------------------+--------------------+\n",
      "|   ONT_NAME|      TAX_TYPE|      PAREA_ROOT_IRI|           CLASS_IRI|\n",
      "+-----------+--------------+--------------------+--------------------+\n",
      "|chembio.owl|     dp_domain|http://www.w3.org...|http://www.biopax...|\n",
      "|chembio.owl|     op_domain|http://www.w3.org...|http://chem2bio2r...|\n",
      "|chembio.owl|     op_domain|http://www.w3.org...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://www.biopax...|http://www.biopax...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     op_domain|http://www.w3.org...|http://www.biopax...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|op_restriction|http://www.biopax...|http://www.biopax...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|op_restriction|http://www.w3.org...|http://www.w3.org...|\n",
      "|chembio.owl|op_restriction|http://chem2bio2r...|http://chem2bio2r...|\n",
      "|chembio.owl|     op_domain|http://www.w3.org...|http://chem2bio2r...|\n",
      "|chembio.owl|     dp_domain|http://chem2bio2r...|http://chem2bio2r...|\n",
      "+-----------+--------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------------------+--------------------+-----------+\n",
      "|   ONT_NAME|           CLASS_IRI|         CLASS_LABEL|   ONT_NAME|\n",
      "+-----------+--------------------+--------------------+-----------+\n",
      "|chembio.owl|http://chem2bio2r...|      ubiquitination|chembio.owl|\n",
      "|chembio.owl|http://www.biopax...|                 dna|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|       hydroxylation|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|         degradation|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|    physicalproperty|chembio.owl|\n",
      "|chembio.owl|http://www.biopax...|      physicalentity|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|              uptake|chembio.owl|\n",
      "|chembio.owl|http://www.w3.org...|               thing|chembio.owl|\n",
      "|chembio.owl|http://www.biopax...|experimentalformv...|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|           stability|chembio.owl|\n",
      "|chembio.owl|http://www.biopax...|evidencecodevocab...|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|    adp-ribosylation|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|        ribosylation|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|     glucuronidation|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|n-linkedglycosyla...|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|              entity|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|            bioassay|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|        localization|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|definition: the p...|chembio.owl|\n",
      "|chembio.owl|http://chem2bio2r...|          ethylation|chembio.owl|\n",
      "+-----------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([])\n",
    "iri_class_labels = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_class_labels = spark.sql(\"SELECT * from class_labels where ONT_NAME = 'chembio.owl'\")\n",
    "# iri_class_labels.describe()\n",
    "\n",
    "sql = \"SELECT distinct ONT_NAME from class_labels where CLASS_IRI = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#ubiquitination'\"\n",
    "df = spark.sql(sql)\n",
    "df.show()\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "df_tax_areas_pareas.join(df, 'ONT_NAME').show()\n",
    "\n",
    "sql2 = \"SELECT * FROM class_labels INNER JOIN people ON class_labels.ONT_NAME=people.ONT_NAME\"\n",
    "dff = spark.sql(sql2)\n",
    "dff.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|     ONT_NAME|\n",
      "+-------------+\n",
      "|   comodi.owl|\n",
      "|cisaviado.obo|\n",
      "|    bcteo.obo|\n",
      "|    cabro.owl|\n",
      "|cisaviado.obo|\n",
      "+-------------+\n",
      "\n",
      "+-------------+\n",
      "|     ONT_NAME|\n",
      "+-------------+\n",
      "|   comodi.owl|\n",
      "|cisaviado.obo|\n",
      "|    bcteo.obo|\n",
      "+-------------+\n",
      "\n",
      "+--------+\n",
      "|ONT_NAME|\n",
      "+--------+\n",
      "+--------+\n",
      "\n",
      "True\n",
      "empty set\n"
     ]
    }
   ],
   "source": [
    "df1=df_tax_areas_pareas.select('ONT_NAME').limit(5)\n",
    "df1.show()\n",
    "df2=df_tax_areas_pareas.select('ONT_NAME').limit(3)\n",
    "df2.show()\n",
    "df2.subtract(df1).show()\n",
    "print( df2.subtract(df1).count()==0)\n",
    "\n",
    "a = set()\n",
    "if not a:\n",
    "    print('empty set')\n",
    "else:\n",
    "    print('not empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "update\n",
      "inside update\n",
      "{'http://www.ebi.ac.uk/efo/efo_0002658', 'http://purl.obolibrary.org/obo/apollo_sv_00000260', 'http://purl.org/incf/ontology/computational_neurosciences/cno_alpha.owl#cno_0000175', 'http://purl.obolibrary.org/obo/apollo_sv_00000112', 'http://www.ebi.ac.uk/efo/efo_0005522', 'http://purl.obolibrary.org/obo/iao_0000098', 'http://www.ebi.ac.uk/efo/efo_0004095', 'http://purl.obolibrary.org/obo/obi_0001933', 'http://purl.obolibrary.org/obo/iao_0000310', 'http://purl.obolibrary.org/obo/iao_0000578', 'http://www.ebi.ac.uk/efo/efo_0005634', 'http://www.ebi.ac.uk/efo/efo_0002605', 'http://purl.obolibrary.org/obo/bco_0000048', 'http://www.ebi.ac.uk/efo/efo_0004101', 'http://www.ebi.ac.uk/efo/efo_0001451', 'http://purl.obolibrary.org/obo/apollo_sv_00000125', 'http://purl.obolibrary.org/obo/apollo_sv_00000282', 'http://semanticscience.org/resource/cheminf_000017', 'http://purl.obolibrary.org/obo/iao_0000028', 'http://purl.obolibrary.org/obo/apollo_sv_00000447', 'http://www.ebi.ac.uk/efo/efo_0000352', 'http://www.ebi.ac.uk/efo/efo_0004110', 'http://www.ebi.ac.uk/efo/efo_0000720', 'http://purl.obolibrary.org/obo/iao_0000006', 'http://purl.obolibrary.org/obo/ddo.owl#uo_0000000', 'http://purl.obolibrary.org/obo/dideo_00000049', 'http://purl.obolibrary.org/obo/apollo_sv_00000202', 'http://purl.obolibrary.org/obo/apollo_sv_00000393', 'http://www.ebi.ac.uk/efo/efo_0000472', 'http://purl.obolibrary.org/obo/fbcv_0000787', 'http://purl.obolibrary.org/obo/dideo_00000023', 'http://purl.obolibrary.org/obo/apollo_sv_00000096', 'http://purl.obolibrary.org/obo/ogms_0000088', 'http://purl.obolibrary.org/obo/iao_0000308', 'http://purl.obolibrary.org/obo/dideo_00000054', 'http://purl.obolibrary.org/obo/apollo_sv_00000296', 'http://www.ebi.ac.uk/efo/efo_0005523', 'http://purl.obolibrary.org/obo/iao_0000101', 'http://purl.obolibrary.org/obo/dideo_00000000', 'http://purl.obolibrary.org/obo/apollo_sv_00000377', 'http://purl.obolibrary.org/obo/iao_0000033', 'http://purl.obolibrary.org/obo/iao_0000027', 'http://purl.obolibrary.org/obo/iao_0000100', 'http://purl.obolibrary.org/obo/apollo_sv_00000436', 'http://purl.obolibrary.org/obo/iao_0020001', 'http://purl.obolibrary.org/obo/apollo_sv_00000375', 'http://purl.obolibrary.org/obo/dideo_00000011', 'http://purl.obolibrary.org/obo/apollo_sv_00000162', 'http://purl.obolibrary.org/obo/apollo_sv_00000215', 'http://purl.obolibrary.org/obo/obi_0000272', 'http://purl.obolibrary.org/obo/dideo_00000053', 'http://purl.obolibrary.org/obo/iao_0020002', 'http://purl.obolibrary.org/obo/dideo_00000014', 'http://purl.obolibrary.org/obo/apollo_sv_00000198', 'http://livercancer.imbi.uni-heidelberg.de/ccont#ccont_0000084', 'http://purl.obolibrary.org/obo/iao_0000009', 'http://purl.obolibrary.org/obo/apollo_sv_00000408', 'http://purl.obolibrary.org/obo/omrse_00000132', 'http://purl.obolibrary.org/obo/apollo_sv_00000214', 'http://www.ebi.ac.uk/efo/efo_0004033', 'http://purl.obolibrary.org/obo/apollo_sv_00000273', 'http://www.ebi.ac.uk/efo/efo_0001742', 'http://purl.obolibrary.org/obo/bco_0000025', 'http://www.ebi.ac.uk/efo/efo_0004034', 'http://www.ebi.ac.uk/efo/efo_0002029', 'http://purl.obolibrary.org/obo/apollo_sv_00000208', 'http://www.ebi.ac.uk/efo/efo_0005521', 'http://purl.obolibrary.org/obo/iao_0000314', 'http://www.ebi.ac.uk/efo/efo_0004444', 'http://purl.obolibrary.org/obo/dideo_00000095', 'http://purl.obolibrary.org/obo/pdro/pdro.owl#pdro_0000123', 'http://purl.obolibrary.org/obo/apollo_sv_00000240', 'http://purl.obolibrary.org/obo/dideo_00000001', 'http://www.ebi.ac.uk/efo/efo_0001444', 'http://purl.obolibrary.org/obo/obi_0000750', 'http://purl.obolibrary.org/obo/geo_000000788', 'http://purl.obolibrary.org/obo/obi_0000785', 'http://purl.obolibrary.org/obo/apollo_sv_00000161', 'http://purl.obolibrary.org/obo/iao_0000429', 'http://purl.obolibrary.org/obo/apollo_sv_00000289', 'http://purl.obolibrary.org/obo/iao_0020000', 'http://purl.obolibrary.org/obo/uo_0000000', 'http://purl.obolibrary.org/obo/eo_0007231', 'http://purl.obolibrary.org/obo/iao_0000300', 'http://purl.obolibrary.org/obo/apollo_sv_00000200', 'http://purl.obolibrary.org/obo/dideo_00000092', 'http://purl.obolibrary.org/obo/dideo_00000022'}\n",
      "{'http://www.ebi.ac.uk/efo/efo_0002658', 'http://purl.obolibrary.org/obo/apollo_sv_00000260', 'http://purl.org/incf/ontology/computational_neurosciences/cno_alpha.owl#cno_0000175', 'http://purl.obolibrary.org/obo/apollo_sv_00000112', 'http://www.ebi.ac.uk/efo/efo_0005522', 'http://purl.obolibrary.org/obo/iao_0000098', 'http://www.ebi.ac.uk/efo/efo_0004095', 'http://purl.obolibrary.org/obo/obi_0001933', 'http://purl.obolibrary.org/obo/iao_0000310', 'http://purl.obolibrary.org/obo/iao_0000578', 'http://www.ebi.ac.uk/efo/efo_0005634', 'http://www.ebi.ac.uk/efo/efo_0002605', 'http://purl.obolibrary.org/obo/bco_0000048', 'http://www.ebi.ac.uk/efo/efo_0004101', 'http://www.ebi.ac.uk/efo/efo_0001451', 'http://purl.obolibrary.org/obo/apollo_sv_00000125', 'http://purl.obolibrary.org/obo/apollo_sv_00000282', 'http://semanticscience.org/resource/cheminf_000017', 'http://purl.obolibrary.org/obo/iao_0000028', 'http://purl.obolibrary.org/obo/apollo_sv_00000447', 'http://www.ebi.ac.uk/efo/efo_0000352', 'http://www.ebi.ac.uk/efo/efo_0004110', 'http://www.ebi.ac.uk/efo/efo_0000720', 'http://purl.obolibrary.org/obo/iao_0000006', 'http://purl.obolibrary.org/obo/ddo.owl#uo_0000000', 'http://purl.obolibrary.org/obo/dideo_00000049', 'http://purl.obolibrary.org/obo/apollo_sv_00000202', 'http://purl.obolibrary.org/obo/apollo_sv_00000393', 'http://www.ebi.ac.uk/efo/efo_0000472', 'http://purl.obolibrary.org/obo/fbcv_0000787', 'http://purl.obolibrary.org/obo/dideo_00000023', 'http://purl.obolibrary.org/obo/apollo_sv_00000096', 'http://purl.obolibrary.org/obo/ogms_0000088', 'http://purl.obolibrary.org/obo/iao_0000308', 'http://purl.obolibrary.org/obo/dideo_00000054', 'http://purl.obolibrary.org/obo/apollo_sv_00000296', 'http://www.ebi.ac.uk/efo/efo_0005523', 'http://purl.obolibrary.org/obo/iao_0000101', 'http://purl.obolibrary.org/obo/dideo_00000000', 'http://purl.obolibrary.org/obo/apollo_sv_00000377', 'http://purl.obolibrary.org/obo/iao_0000033', 'http://purl.obolibrary.org/obo/iao_0000027', 'http://purl.obolibrary.org/obo/iao_0000100', 'http://purl.obolibrary.org/obo/apollo_sv_00000436', 'http://purl.obolibrary.org/obo/iao_0020001', 'http://purl.obolibrary.org/obo/apollo_sv_00000375', 'http://purl.obolibrary.org/obo/dideo_00000011', 'http://purl.obolibrary.org/obo/apollo_sv_00000162', 'http://purl.obolibrary.org/obo/apollo_sv_00000215', 'http://purl.obolibrary.org/obo/obi_0000272', 'http://purl.obolibrary.org/obo/dideo_00000053', 'http://purl.obolibrary.org/obo/iao_0020002', 'http://purl.obolibrary.org/obo/dideo_00000014', 'http://purl.obolibrary.org/obo/apollo_sv_00000198', 'http://livercancer.imbi.uni-heidelberg.de/ccont#ccont_0000084', 'http://purl.obolibrary.org/obo/iao_0000009', 'http://purl.obolibrary.org/obo/apollo_sv_00000408', 'http://purl.obolibrary.org/obo/omrse_00000132', 'http://purl.obolibrary.org/obo/apollo_sv_00000214', 'http://www.ebi.ac.uk/efo/efo_0004033', 'http://purl.obolibrary.org/obo/apollo_sv_00000273', 'http://www.ebi.ac.uk/efo/efo_0001742', 'http://purl.obolibrary.org/obo/bco_0000025', 'http://www.ebi.ac.uk/efo/efo_0004034', 'http://www.ebi.ac.uk/efo/efo_0002029', 'http://purl.obolibrary.org/obo/apollo_sv_00000208', 'http://www.ebi.ac.uk/efo/efo_0005521', 'http://purl.obolibrary.org/obo/iao_0000314', 'http://www.ebi.ac.uk/efo/efo_0004444', 'http://purl.obolibrary.org/obo/dideo_00000095', 'http://purl.obolibrary.org/obo/pdro/pdro.owl#pdro_0000123', 'http://purl.obolibrary.org/obo/apollo_sv_00000240', 'http://purl.obolibrary.org/obo/dideo_00000001', 'http://www.ebi.ac.uk/efo/efo_0001444', 'http://purl.obolibrary.org/obo/obi_0000750', 'http://purl.obolibrary.org/obo/geo_000000788', 'http://purl.obolibrary.org/obo/obi_0000785', 'http://purl.obolibrary.org/obo/apollo_sv_00000161', 'http://purl.obolibrary.org/obo/iao_0000429', 'http://purl.obolibrary.org/obo/apollo_sv_00000289', 'http://purl.obolibrary.org/obo/iao_0020000', 'http://purl.obolibrary.org/obo/uo_0000000', 'http://purl.obolibrary.org/obo/eo_0007231', 'http://purl.obolibrary.org/obo/iao_0000300', 'http://purl.obolibrary.org/obo/apollo_sv_00000200', 'http://purl.obolibrary.org/obo/dideo_00000092', 'http://purl.obolibrary.org/obo/dideo_00000022'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://www.biopax.org/release/biopax-level3.owl#chemicalstructure', 'http://chem2bio2rdf.org/chem2bio2rdf.owl#drugtreament'}\n",
      "{'http://www.biopax.org/release/biopax-level3.owl#chemicalstructure', 'http://chem2bio2rdf.org/chem2bio2rdf.owl#drugtreament'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#init 5 tables\n",
    "schema = StructType([])\n",
    "iri_class_labels = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_class_hier = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas_concepts = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas_pareas = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "\n",
    "#init ontologies list\n",
    "global_ontList=sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "\n",
    "\n",
    "class IRIRelatedTables:\n",
    "    \n",
    "    \n",
    "    def __init__(self, iri):\n",
    "        self.iri = iri\n",
    "        self.local_ontList = self.getOntNames()\n",
    "        self.initializeTables()\n",
    "        \n",
    "    def initializeTables(self):\n",
    "        global iri_class_labels,\\\n",
    "        iri_class_hier,\\\n",
    "        iri_tax_areas,\\\n",
    "        iri_tax_areas_concepts,\\\n",
    "        iri_tax_areas_pareas,\\\n",
    "        global_ontList\n",
    "        \n",
    "        if global_ontList.count()==0:\n",
    "            #initialize 5 tables\n",
    "            print('init')\n",
    "            iri_class_labels = self.initializeTable(df_class_labels)\n",
    "            iri_class_hier = self.initializeTable(df_class_hier)\n",
    "            iri_tax_areas = self.initializeTable(df_tax_areas)\n",
    "            iri_tax_areas_concepts = self.initializeTable(df_tax_areas_concepts)\n",
    "            iri_tax_areas_pareas = self.initializeTable(df_tax_areas_pareas)\n",
    "            global_ontList = self.getOntNames()\n",
    "        else:\n",
    "            print('update')\n",
    "            ontNames = self.local_ontList.subtract(global_ontList)\n",
    "            if ontNames.count()!=0:\n",
    "                print('inside update')\n",
    "                #update 5 tables\n",
    "                iri_class_labels = self.updateTable(iri_class_labels, df_class_labels, ontNames) \n",
    "                iri_class_hier = self.updateTable(iri_class_hier, df_class_hier, ontNames)\n",
    "                iri_tax_areas = self.updateTable(iri_tax_areas, df_tax_areas, ontNames)\n",
    "                iri_tax_areas_concepts = self.updateTable(iri_tax_areas_concepts, df_tax_areas_concepts, ontNames)\n",
    "                iri_tax_areas_pareas = self.updateTable(iri_tax_areas_pareas, df_tax_areas_pareas, ontNames)\n",
    "            global_ontList = global_ontList.union(self.local_ontList)\n",
    "        \n",
    "    def initializeTable(self, df):\n",
    "        try:\n",
    "            ontNames = self.getOntNames() \n",
    "            return df.join(ontNames, 'ONT_NAME').distinct()\n",
    "        except:\n",
    "            print('iri has no corresponding ontology found!')\n",
    "            raise\n",
    "\n",
    "    def updateTable(self, df, dff, ontNames):\n",
    "        try:\n",
    "            dff= dff.join(ontNames, 'ONT_NAME').distinct()\n",
    "            return df.union(dff)\n",
    "        except:\n",
    "            print('iri has no corresponding ontology found!')\n",
    "            raise\n",
    "        \n",
    "    def getOntNames(self):\n",
    "        sql = \"SELECT distinct ONT_NAME from class_labels where CLASS_IRI = '\"+ self.iri +\"'\"\n",
    "        df = spark.sql(sql)\n",
    "        return df\n",
    "\n",
    "iri= 'http://purl.obolibrary.org/obo/iao_0000030'\n",
    "test = IRIRelatedTables(iri)\n",
    "# print(iri_class_labels.count())\n",
    "# print(iri_class_hier.count())\n",
    "\n",
    "iri2 = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\n",
    "test2 = IRIRelatedTables(iri2)\n",
    "# print(iri_class_labels.count())\n",
    "# print(iri_class_hier.count())\n",
    "# def getIRIOntTables(iri, df_table):\n",
    "#     df_table.createOrReplaceTempView(\"tabels\")\n",
    "#     onts = getOnts(iri)\n",
    "#     print(onts)\n",
    "#     if onts:\n",
    "#         for idx, ont in enumerate(onts):\n",
    "#             if idx == 0:\n",
    "#                 dff = spark.sql(\"SELECT * from tabels where ONT_NAME = '\" + ont +\"'\")\n",
    "#                 df = dff\n",
    "#             else:\n",
    "#                 dff = spark.sql(\"SELECT * from tabels where ONT_NAME = '\" + ont +\"'\")\n",
    "#                 df = df.union(dff)\n",
    "#         return df.collect()\n",
    "#     raise Exception('No ontology found!')\n",
    "    \n",
    "\n",
    "# http://purl.obolibrary.org/obo/iao_0000030\n",
    "# http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay\n",
    "# iri = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\n",
    "# print(getIRIOntTables(iri).count())\n",
    "\n",
    "\n",
    "# def getLabelFast(iri):\n",
    "#     result =[]\n",
    "#     ontTable=getIRIOntTables(iri)\n",
    "#     labels = ontTable.filter(ontTable.CLASS_IRI==iri).select('CLASS_IRI','CLASS_LABEL').distinct().collect()\n",
    "#     for row in labels:\n",
    "#         if not isIRIEqualLabel(row[\"CLASS_IRI\"], row['CLASS_LABEL']):\n",
    "#             result.append(row[\"CLASS_LABEL\"])\n",
    "#     return result\n",
    "\n",
    "def getChildrenFast(iri):\n",
    "    result = set()\n",
    "    children = iri_class_hier.filter(iri_class_hier.PARENT_CLASS_IRI==iri).distinct().collect()\n",
    "    for row in children:\n",
    "        result.add(row['CLASS_IRI'])\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "print(getChildrenFast(iri))\n",
    "print(getChildrenFast(iri2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update\n",
      "inside update\n",
      "{'http://purl.obolibrary.org/obo/chebi_133769', 'http://purl.obolibrary.org/obo/chebi_62945', 'http://purl.obolibrary.org/obo/chebi_133772', 'http://purl.obolibrary.org/obo/chebi_59326', 'http://purl.obolibrary.org/obo/chebi_133771', 'http://purl.obolibrary.org/obo/chebi_133768'}\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133769\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_62945\n",
      "{'http://purl.obolibrary.org/obo/chebi_137988', 'http://purl.obolibrary.org/obo/chebi_136539', 'http://purl.obolibrary.org/obo/chebi_90696', 'http://purl.obolibrary.org/obo/chebi_57445'}\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_137988\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_136539\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90696\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57445\n",
      "{'http://purl.obolibrary.org/obo/chebi_137989'}\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_137989\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133772\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133771\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_59326\n",
      "{'http://purl.obolibrary.org/obo/chebi_133409', 'http://purl.obolibrary.org/obo/chebi_57400', 'http://purl.obolibrary.org/obo/chebi_90801', 'http://purl.obolibrary.org/obo/chebi_132149', 'http://purl.obolibrary.org/obo/chebi_57401', 'http://purl.obolibrary.org/obo/chebi_79010', 'http://purl.obolibrary.org/obo/chebi_57407', 'http://purl.obolibrary.org/obo/chebi_133396', 'http://purl.obolibrary.org/obo/chebi_85173', 'http://purl.obolibrary.org/obo/chebi_133370', 'http://purl.obolibrary.org/obo/chebi_57397', 'http://purl.obolibrary.org/obo/chebi_133391', 'http://purl.obolibrary.org/obo/chebi_77768', 'http://purl.obolibrary.org/obo/chebi_57406', 'http://purl.obolibrary.org/obo/chebi_133411', 'http://purl.obolibrary.org/obo/chebi_57398', 'http://purl.obolibrary.org/obo/chebi_57402', 'http://purl.obolibrary.org/obo/chebi_136663', 'http://purl.obolibrary.org/obo/chebi_134577', 'http://purl.obolibrary.org/obo/chebi_133132', 'http://purl.obolibrary.org/obo/chebi_133134', 'http://purl.obolibrary.org/obo/chebi_133084', 'http://purl.obolibrary.org/obo/chebi_57405', 'http://purl.obolibrary.org/obo/chebi_133374', 'http://purl.obolibrary.org/obo/chebi_57408', 'http://purl.obolibrary.org/obo/chebi_133422', 'http://purl.obolibrary.org/obo/chebi_133393', 'http://purl.obolibrary.org/obo/chebi_85072', 'http://purl.obolibrary.org/obo/chebi_133423', 'http://purl.obolibrary.org/obo/chebi_90797', 'http://purl.obolibrary.org/obo/chebi_57403', 'http://purl.obolibrary.org/obo/chebi_90827', 'http://purl.obolibrary.org/obo/chebi_133425', 'http://purl.obolibrary.org/obo/chebi_90793', 'http://purl.obolibrary.org/obo/chebi_136653', 'http://purl.obolibrary.org/obo/chebi_133451', 'http://purl.obolibrary.org/obo/chebi_606564', 'http://purl.obolibrary.org/obo/chebi_57399', 'http://purl.obolibrary.org/obo/chebi_79072', 'http://purl.obolibrary.org/obo/chebi_133133', 'http://purl.obolibrary.org/obo/chebi_133376', 'http://purl.obolibrary.org/obo/chebi_57404', 'http://purl.obolibrary.org/obo/chebi_133408', 'http://purl.obolibrary.org/obo/chebi_82629', 'http://purl.obolibrary.org/obo/chebi_136661', 'http://purl.obolibrary.org/obo/chebi_133392', 'http://purl.obolibrary.org/obo/chebi_85236', 'http://purl.obolibrary.org/obo/chebi_133424', 'http://purl.obolibrary.org/obo/chebi_137987'}\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133409\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57400\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90801\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_132149\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57401\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_79010\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57407\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133396\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_85173\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133370\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57397\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133391\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_77768\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57406\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133411\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57398\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57402\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_136663\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_134577\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133132\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133134\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133084\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57405\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133374\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57408\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133422\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133393\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_85072\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133423\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90797\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57403\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90827\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133425\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90793\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_136653\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133451\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_606564\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57399\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_79072\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133133\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133376\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57404\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133408\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_82629\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_136661\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133392\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_85236\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133424\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_137987\n",
      "set()\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133768\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "def getAllChildren(iri, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "    result = []\n",
    "    pair = []\n",
    "    for child_iri in getChildrenFast(iri) - visited:\n",
    "        print(\"get child: \", child_iri)\n",
    "        if child_iri:\n",
    "            result.append(child_iri)\n",
    "            pair.append((child_iri, iri))\n",
    "            result1, pair1 = getAllChildren(child_iri, visited)\n",
    "            result += result1\n",
    "            pair += pair1\n",
    "            visited.add(child_iri)\n",
    "            \n",
    "    return result, pair\n",
    "\n",
    "iri= 'http://purl.obolibrary.org/obo/chebi_62943'\n",
    "test = IRIRelatedTables(iri)\n",
    "c_vertices, c_edges = getAllChildren(iri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(ONT_NAME='cno_acronym.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='cogpo.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='apollo-sv.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='information content entity'), Row(ONT_NAME='cdao.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='aero.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='bco.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='information content entity'), Row(ONT_NAME='chmo.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='information content entity'), Row(ONT_NAME='ccont.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='ddo.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='cheminf.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='dideo.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030'), Row(ONT_NAME='dron.owl', CLASS_IRI='http://purl.obolibrary.org/obo/iao_0000030', CLASS_LABEL='iao 0000030')]\n"
     ]
    }
   ],
   "source": [
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "\n",
    "iri = \"http://purl.obolibrary.org/obo/iao_0000030\"\n",
    "print(spark.sql(\"SELECT * from class_labels where CLASS_IRI = '\" + iri +\"'\").collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL=df_class_hier.join(df_class_labels, 'CLASS_IRI').select(df_class_hier.CLASS_IRI, df_class_labels.CLASS_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.count()\n",
    "df_IRI_LABEL.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.groupBy(\"CLASS_IRI\").count().sort(\"count\", ascending=False).limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.show(10,truncate= True)\n",
    "result = df_IRI_LABEL.where(df_IRI_LABEL.CLASS_IRI == 'http://purl.obolibrary.org/obo/iao_0000030').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.count())\n",
    "result.collect()[1]['CLASS_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result.collect():\n",
    "    print(row['CLASS_IRI'], row['CLASS_LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def isIRIEqualLabel(iri, label):\n",
    "    iri = iri.split('/')[-1].replace('_',' ')\n",
    "    return label ==iri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result.collect():\n",
    "    if not isIRIEqualLabel(row[0], row[1]):\n",
    "        print(row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIRI(label):\n",
    "    result = []\n",
    "    iris = df_class_labels.filter(df_class_labels.CLASS_LABEL==label).select('CLASS_IRI','CLASS_LABEL').distinct().collect()\n",
    "    for row in iris:\n",
    "        if not isIRIEqualLabel(row[\"CLASS_IRI\"], row['CLASS_LABEL']):\n",
    "            result.append(row[\"CLASS_IRI\"])\n",
    "    return result\n",
    "\n",
    "def getLabel(iri):\n",
    "    result =[]\n",
    "    labels = df_class_labels.filter(df_class_labels.CLASS_IRI==iri).select('CLASS_IRI','CLASS_LABEL').distinct().collect()\n",
    "    for row in labels:\n",
    "        if not isIRIEqualLabel(row[\"CLASS_IRI\"], row['CLASS_LABEL']):\n",
    "            result.append(row[\"CLASS_LABEL\"])\n",
    "    return result\n",
    "\n",
    "def getOnts(iri):\n",
    "    result =[]\n",
    "    ont_names = df_class_labels.filter(df_class_labels.CLASS_IRI==iri).select('ONT_NAME').distinct().collect()\n",
    "    for row in ont_names:\n",
    "        result.append(row[\"ONT_NAME\"])\n",
    "    return result\n",
    "            \n",
    "\n",
    "def getParents(iri):\n",
    "    result =set()\n",
    "    if iri == 'http://www.w3.org/2002/07/owl#thing':\n",
    "        return result\n",
    "    print(\"get parent for: \", iri) \n",
    "    parents = df_class_hier.filter(df_class_hier.CLASS_IRI==iri).distinct().collect()\n",
    "    for row in parents:\n",
    "        result.add(row['PARENT_CLASS_IRI'])\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def getChildren(iri):\n",
    "    result =set()\n",
    "    children = df_class_hier.filter(df_class_hier.PARENT_CLASS_IRI==iri).distinct().collect()\n",
    "    for row in children:\n",
    "        result.add(row['CLASS_IRI'])\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def getArea(iri, tax_type = 'op_restriction'):\n",
    "    result = df_tax_areas_concepts.filter((df_tax_areas_concepts.TAX_TYPE==tax_type)&\\\n",
    "                                          (df_tax_areas_concepts.CLASS_IRI==iri) & \\\n",
    "                                          (df_tax_areas_concepts.AREA_ID!='[empty set]'))\\\n",
    "    .join(df_tax_areas,'AREA_ID').drop(df_tax_areas.TAX_TYPE)\n",
    "    area = result.select('TAX_TYPE','AREA_ID', 'AREA_NAME', 'AREA_LEVEL').collect()\n",
    "#     area = result.collect()\n",
    "    return area\n",
    "\n",
    "def getOntName(iri):\n",
    "    return ont\n",
    "\n",
    "def getPArea(iri, tax_type = 'op_restriction'):\n",
    "    result = df_tax_areas_pareas.filter((df_tax_areas_pareas.TAX_TYPE==tax_type)&\\\n",
    "                                        (df_tax_areas_pareas.CLASS_IRI==iri) & \\\n",
    "                                          (df_tax_areas_pareas.PAREA_ROOT_IRI!='[empty set]'))\n",
    "    parea = result.drop('ONT_NAME').distinct().collect()\n",
    "    return parea\n",
    "\n",
    "def getAreaLevel(iri, tax_type = 'op_restriction'):\n",
    "    df_tax_areas_concepts2=df_tax_areas_concepts.filter((df_tax_areas_concepts.TAX_TYPE==tax_type)&\\\n",
    "                                                        (df_tax_areas_concepts.CLASS_IRI == iri)& \\\n",
    "                                                          (df_tax_areas_concepts.AREA_ID!='[empty set]'))\n",
    "    \n",
    "    result = df_tax_areas.join(df_tax_areas_concepts2, 'AREA_ID').drop('ONT_NAME').distinct().first()\n",
    "    \n",
    "    if not result:\n",
    "        return 0\n",
    "    else:\n",
    "        return result['AREA_LEVEL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAreaLevel(\"http://purl.obolibrary.org/obo/apollo_sv_00000144\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getIRI(\"information content entity\"))\n",
    "print(getLabel(\"http://purl.obolibrary.org/obo/iao_0000030\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getArea('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "getChildren('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "# result = df_tax_areas_concepts.filter(df_tax_areas_concepts.CLASS_IRI=='http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "\n",
    "# result.filter(df_tax_areas_concepts.AREA_ID!='[empty set]').show()\n",
    "getParents('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPArea('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_hier\n",
    "df_class_labels\n",
    "df_tax_areas\n",
    "df_tax_areas_concepts\n",
    "df_tax_areas_pareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPArea('http://www.w3.org/2002/07/owl#thing')\n",
    "getParents('http://www.w3.org/2002/07/owl#thing')\n",
    "getParents('http://www.ifomis.org/bfo/1.1#entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPAreaParent(iri, depth=1):\n",
    "    result = []\n",
    "    for i in range(depth):\n",
    "        for row in getPArea(iri):\n",
    "            result.append((iri, row['PAREA_ROOT_IRI']))\n",
    "            result + getPAreaParent(getParents(row['PAREA_ROOT_IRI']))\n",
    "            \n",
    "def getAreaParent(iri, depth):\n",
    "    parents= []\n",
    "\n",
    "    \n",
    "    \n",
    "def getPAreaChildren(iri, depth=1):\n",
    "    result = []\n",
    "    for i in range(depth):\n",
    "        for row in getPArea(iri):\n",
    "            result.append((row['PAREA_ROOT_IRI'], iri))\n",
    "            result + getPAreaChilren(getChildren(row['PAREA_ROOT_IRI']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get child:  http://purl.obolibrary.org/obo/chebi_133769\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_62945\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_137988\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_136539\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_90696\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_57445\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_137989\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133772\n",
      "get child:  http://purl.obolibrary.org/obo/chebi_133771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-8a2728e10ebc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mc_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://purl.obolibrary.org/obo/chebi_62943'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-8a2728e10ebc>\u001b[0m in \u001b[0;36mgetAllChildren\u001b[0;34m(iri, visited)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_iri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_iri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mresult1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAllChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_iri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresult1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mpair\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpair1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-8a2728e10ebc>\u001b[0m in \u001b[0;36mgetAllChildren\u001b[0;34m(iri, visited)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchild_iri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miri\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get child: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchild_iri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchild_iri\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f1740ebc3a3f>\u001b[0m in \u001b[0;36mgetChildren\u001b[0;34m(iri)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetChildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_class_hier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_class_hier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARENT_CLASS_IRI\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0miri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CLASS_IRI'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/share/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def getAllChildren(iri, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "    result = []\n",
    "    pair = []\n",
    "    for child_iri in getChildren(iri) - visited:\n",
    "        print(\"get child: \",child_iri)\n",
    "        if child_iri:\n",
    "            result.append(child_iri)\n",
    "            pair.append((child_iri, iri))\n",
    "            result1, pair1 = getAllChildren(child_iri, visited)\n",
    "            result += result1\n",
    "            pair += pair1\n",
    "            visited.add(child_iri)\n",
    "            \n",
    "    return result, pair\n",
    "c_vertices, c_edges = getAllChildren('http://purl.obolibrary.org/obo/chebi_62943')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParents(iri, visited = None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "\n",
    "    result = []\n",
    "    pair = []\n",
    "    if iri != 'http://www.w3.org/2002/07/owl#thing':\n",
    "        for parent_iri in getParents(iri) - visited:\n",
    "            print(\"get parent: \", parent_iri)\n",
    "            if parent_iri:\n",
    "                result.append(parent_iri)\n",
    "                pair.append((iri, parent_iri))\n",
    "                result1, pair1 = getAllParents(parent_iri, visited)\n",
    "                result += result1\n",
    "                pair += pair1\n",
    "                visited.add(parent_iri)\n",
    "    return result, pair\n",
    "\n",
    "p_vertices, p_edges = getAllParents('http://purl.obolibrary.org/obo/chebi_62943')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "g = ig.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_vertex(name = 'http://purl.obolibrary.org/obo/chebi_62943')\n",
    "g.add_vertices(p_vertices)\n",
    "\n",
    "# for vertex in vertices:\n",
    "#     g.add_vertex(name=vertex)\n",
    "\n",
    "N=g.vcount()\n",
    "print('total number of vertices imported: ' , N)\n",
    "print(p_edges)\n",
    "\n",
    "g.add_edges(p_edges)\n",
    "\n",
    "L= g.ecount()\n",
    "print('added # of edges: ', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.add_vertex(name = 'http://purl.obolibrary.org/obo/chebi_62943')\n",
    "g.add_vertices(c_vertices)\n",
    "\n",
    "# for vertex in vertices:\n",
    "#     g.add_vertex(name=vertex)\n",
    "\n",
    "N=g.vcount()\n",
    "print('total number of vertices imported: ' , N)\n",
    "print(c_edges)\n",
    "\n",
    "g.add_edges(c_edges)\n",
    "\n",
    "L= g.ecount()\n",
    "print('added # of edges: ', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "group=[]\n",
    "for node in g.vs:\n",
    "    labels.append(getLabel(node['name']))\n",
    "    group.append(getAreaLevel(node['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g.vs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layt=g.layout_auto(dim=3)\n",
    "layt[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\n",
    "Yn=[layt[k][1] for k in range(N)]# y-coordinates\n",
    "Zn=[layt[k][2] for k in range(N)]# z-coordinates\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "for e in g.es:\n",
    "    e=e.tuple\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    Ze+=[layt[e[0]][2],layt[e[1]][2], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1=Scatter3d(x=Xe,\n",
    "               y=Ye,\n",
    "               z=Ze,\n",
    "               mode='lines',\n",
    "               line=Line(color='rgb(125,125,125)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "trace2=Scatter3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "               mode='markers',\n",
    "               name='actors',\n",
    "               marker=Marker(symbol='dot',\n",
    "                             size=6,\n",
    "                             color=group,\n",
    "                             colorscale='Viridis',\n",
    "                             line=Line(color='rgb(50,50,50)', width=0.5)\n",
    "                             ),\n",
    "               text=labels,\n",
    "               hoverinfo='text'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = Layout(\n",
    "         title=\"Network of coappearances of characters in Victor Hugo's novel<br> Les Miserables (3D visualization)\",\n",
    "         width=1000,\n",
    "         height=1000,\n",
    "         showlegend=False,\n",
    "         scene=Scene(\n",
    "         xaxis=XAxis(axis),\n",
    "         yaxis=YAxis(axis),\n",
    "         zaxis=ZAxis(axis),\n",
    "        ),\n",
    "     margin=Margin(\n",
    "        t=100\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    annotations=Annotations([\n",
    "           Annotation(\n",
    "           showarrow=False,\n",
    "            text=\"Data source: <a href='http://bost.ocks.org/mike/miserables/miserables.json'>[1] miserables.json</a>\",\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            x=0,\n",
    "            y=0.1,\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            font=Font(\n",
    "            size=14\n",
    "            )\n",
    "            )\n",
    "        ]),    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Data([trace1, trace2])\n",
    "fig=Figure(data=data, layout=layout)\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "py.offline.iplot(fig, filename='Les-Miserables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
