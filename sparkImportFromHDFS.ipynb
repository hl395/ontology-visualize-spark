{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.1</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package already installed: graphframes:graphframes:0.5.0-spark2.1-s_2.11\n",
      "Package already installed: com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2\n",
      "Package already installed: com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pixiedust\n",
    "\n",
    "if sc.version.startswith('1.6.'):  # Spark 1.6\n",
    "    pixiedust.installPackage(\"graphframes:graphframes:0.5.0-spark1.6-s_2.11\")\n",
    "elif sc.version.startswith('2.'):  # Spark 2.1, 2.0\n",
    "    pixiedust.installPackage(\"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "\n",
    "\n",
    "pixiedust.installPackage(\"com.typesafe.scala-logging:scala-logging-api_2.11:2.1.2\")\n",
    "pixiedust.installPackage(\"com.typesafe.scala-logging:scala-logging-slf4j_2.11:2.1.2\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# import os\n",
    "\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages graphframes:graphframes:0.5.0-spark2.1-s_2.11 pyspark-shell'\n",
    "\n",
    "\n",
    "# Build the SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"sparkPlot\") \\\n",
    "   .config(\"spark.executor.memory\", \"2gb\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "# spark.conf.set(\"spark.jars.packages\", \"graphframes:graphframes:0.5.0-spark2.1-s_2.11\")\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809619\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- PARENT_CLASS_IRI: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"PARENT_CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_class_hier= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_HIERARCHY.csv\")\n",
    "    \n",
    "    \n",
    "print(df_class_hier.count())\n",
    "df_class_hier.printSchema()\n",
    "df_class_hier=df_class_hier.distinct()\n",
    "# df_class_hier.createGlobalTempView(\"class_hier\")\n",
    "df_class_hier.createOrReplaceTempView(\"class_hier\")\n",
    "\n",
    "# iri = \"http://purl.obolibrary.org/obo/iao_0000030\"\n",
    "# print(spark.sql(\"SELECT * from class_hier where CLASS_IRI = '\" + iri +\"'\").collect())\n",
    "# print(df_class_hier.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711444\n",
      "root\n",
      " |-- ONT_NAME: string (nullable = true)\n",
      " |-- CLASS_IRI: string (nullable = true)\n",
      " |-- CLASS_LABEL: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType()),\n",
    "    StructField(\"CLASS_LABEL\", StringType())\n",
    "])\n",
    "\n",
    "df_class_labels= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/ONT_CLASS_LABELS.csv\")\n",
    "\n",
    "    \n",
    "print(df_class_labels.count())\n",
    "df_class_labels.printSchema()\n",
    "df_class_labels=df_class_labels.distinct()\n",
    "# df_class_labels.createGlobalTempView(\"class_labels\")\n",
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"AREA_NAME\", StringType()),\n",
    "    StructField(\"AREA_LEVEL\", IntegerType())\n",
    "])\n",
    "\n",
    "df_tax_areas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS.csv\")\n",
    "\n",
    "print(df_tax_areas.count())\n",
    "df_tax_areas.printSchema()\n",
    "df_tax_areas=df_tax_areas.distinct()\n",
    "# df_tax_areas.createGlobalTempView(\"tax_areas\")\n",
    "df_tax_areas.createOrReplaceTempView(\"tax_areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"AREA_ID\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_concepts= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_CONCEPTS.csv\")\n",
    "\n",
    "print(df_tax_areas_concepts.count())\n",
    "df_tax_areas_concepts.printSchema()\n",
    "df_tax_areas_concepts=df_tax_areas_concepts.distinct()\n",
    "# df_tax_areas_concepts.createGlobalTempView(\"tax_areas_concepts\")\n",
    "df_tax_areas_concepts.createOrReplaceTempView(\"tax_areas_concepts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ONT_NAME\", StringType()),\n",
    "    StructField(\"TAX_TYPE\", StringType()),\n",
    "    StructField(\"PAREA_ROOT_IRI\", StringType()),\n",
    "    StructField(\"CLASS_IRI\", StringType())\n",
    "])\n",
    "\n",
    "df_tax_areas_pareas= spark.read \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .csv(\"hdfs://localhost:9000/TAX_AREAS_PAREAS.csv\")\n",
    "\n",
    "print(df_tax_areas_pareas.count())\n",
    "df_tax_areas_pareas.printSchema()\n",
    "df_tax_areas_pareas=df_tax_areas_pareas.distinct()\n",
    "# df_tax_areas_pareas.createGlobalTempView(\"tax_areas_pareas\")\n",
    "df_tax_areas_pareas.createOrReplaceTempView(\"tax_areas_pareas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([])\n",
    "iri_class_labels = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_class_labels = spark.sql(\"SELECT * from class_labels where ONT_NAME = 'chembio.owl'\")\n",
    "# iri_class_labels.describe()\n",
    "\n",
    "sql = \"SELECT distinct ONT_NAME from class_labels where CLASS_IRI = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#ubiquitination'\"\n",
    "df = spark.sql(sql)\n",
    "df.show()\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "df_tax_areas_pareas.join(df, 'ONT_NAME').show()\n",
    "\n",
    "sql2 = \"SELECT * FROM class_labels INNER JOIN people ON class_labels.ONT_NAME=people.ONT_NAME\"\n",
    "dff = spark.sql(sql2)\n",
    "dff.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df_tax_areas_pareas.select('ONT_NAME').limit(5)\n",
    "df1.show()\n",
    "df2=df_tax_areas_pareas.select('ONT_NAME').limit(3)\n",
    "df2.show()\n",
    "df2.subtract(df1).show()\n",
    "print( df2.subtract(df1).count()==0)\n",
    "\n",
    "a = set()\n",
    "if not a:\n",
    "    print('empty set')\n",
    "else:\n",
    "    print('not empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init 5 tables\n",
    "schema = StructType([])\n",
    "iri_class_labels = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_class_hier = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas_concepts = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "iri_tax_areas_pareas = sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "\n",
    "#init ontologies list\n",
    "global_ontList=sqlContext.createDataFrame(sc.emptyRDD(), schema)\n",
    "\n",
    "\n",
    "class IRIRelatedTables:\n",
    "    \n",
    "    \n",
    "    def __init__(self, iri):\n",
    "        self.iri = iri\n",
    "        self.local_ontList = self.getOntNames()\n",
    "        self.initializeTables()\n",
    "        \n",
    "    def initializeTables(self):\n",
    "        global iri_class_labels,\\\n",
    "        iri_class_hier,\\\n",
    "        iri_tax_areas,\\\n",
    "        iri_tax_areas_concepts,\\\n",
    "        iri_tax_areas_pareas,\\\n",
    "        global_ontList\n",
    "        \n",
    "        if global_ontList.count()==0:\n",
    "            #initialize 5 tables\n",
    "            print('init')\n",
    "            iri_class_labels = self.initializeTable(df_class_labels)\n",
    "            iri_class_hier = self.initializeTable(df_class_hier)\n",
    "            iri_tax_areas = self.initializeTable(df_tax_areas)\n",
    "            iri_tax_areas_concepts = self.initializeTable(df_tax_areas_concepts)\n",
    "            iri_tax_areas_pareas = self.initializeTable(df_tax_areas_pareas)\n",
    "            global_ontList = self.getOntNames()\n",
    "        else:\n",
    "            print('update')\n",
    "            ontNames = self.local_ontList.subtract(global_ontList)\n",
    "            if ontNames.count()!=0:\n",
    "                print('inside update')\n",
    "                #update 5 tables\n",
    "                iri_class_labels = self.updateTable(iri_class_labels, df_class_labels, ontNames) \n",
    "                iri_class_hier = self.updateTable(iri_class_hier, df_class_hier, ontNames)\n",
    "                iri_tax_areas = self.updateTable(iri_tax_areas, df_tax_areas, ontNames)\n",
    "                iri_tax_areas_concepts = self.updateTable(iri_tax_areas_concepts, df_tax_areas_concepts, ontNames)\n",
    "                iri_tax_areas_pareas = self.updateTable(iri_tax_areas_pareas, df_tax_areas_pareas, ontNames)\n",
    "            global_ontList = global_ontList.union(self.local_ontList)\n",
    "        \n",
    "    def initializeTable(self, df):\n",
    "        try:\n",
    "            ontNames = self.getOntNames() \n",
    "            return df.join(ontNames, 'ONT_NAME').distinct()\n",
    "        except:\n",
    "            print('iri has no corresponding ontology found!')\n",
    "            raise\n",
    "\n",
    "    def updateTable(self, df, dff, ontNames):\n",
    "        try:\n",
    "            dff= dff.join(ontNames, 'ONT_NAME').distinct()\n",
    "            return df.union(dff)\n",
    "        except:\n",
    "            print('iri has no corresponding ontology found!')\n",
    "            raise\n",
    "        \n",
    "    def getOntNames(self):\n",
    "        sql = \"SELECT distinct ONT_NAME from class_labels where CLASS_IRI = '\"+ self.iri +\"'\"\n",
    "        df = spark.sql(sql)\n",
    "        return df\n",
    "\n",
    "iri= 'http://purl.obolibrary.org/obo/iao_0000030'\n",
    "test = IRIRelatedTables(iri)\n",
    "# print(iri_class_labels.count())\n",
    "# print(iri_class_hier.count())\n",
    "\n",
    "iri2 = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\n",
    "test2 = IRIRelatedTables(iri2)\n",
    "\n",
    "def getChildrenFast(iri):\n",
    "    result = set()\n",
    "    children = iri_class_hier.filter(iri_class_hier.PARENT_CLASS_IRI==iri).distinct().collect()\n",
    "    for row in children:\n",
    "        result.add(row['CLASS_IRI'])\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "print(getChildrenFast(iri))\n",
    "print(getChildrenFast(iri2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iri = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\n",
    "iri= 'http://purl.obolibrary.org/obo/iao_0000030'\n",
    "df_hier = df_class_hier.rdd.map(lambda x : (x[1], x[2])).distinct().toDF(['src', 'dst'])\n",
    "\n",
    "df_label = df_class_labels.rdd.map(lambda x: (x[1], x[2])).distinct().toDF(['id', 'label'])\n",
    "# df_hier.reduceByKey(lambda x, y: x +y ).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                  id|inDegree|\n",
      "+--------------------+--------+\n",
      "|http://purl.oboli...|       6|\n",
      "|http://purl.oboli...|       5|\n",
      "|http://purl.oboli...|       3|\n",
      "|http://purl.oboli...|       1|\n",
      "|http://purl.oboli...|       6|\n",
      "|http://ncicb.nci....|      10|\n",
      "|http://www.orpha....|       3|\n",
      "|http://purl.oboli...|       7|\n",
      "|http://ncicb.nci....|      23|\n",
      "|http://purl.oboli...|      16|\n",
      "|http://purl.oboli...|       2|\n",
      "|http://purl.oboli...|       1|\n",
      "|http://purl.oboli...|       1|\n",
      "|http://purl.oboli...|       8|\n",
      "|http://purl.oboli...|      28|\n",
      "|http://purl.oboli...|       3|\n",
      "|http://purl.oboli...|       1|\n",
      "|http://purl.oboli...|      56|\n",
      "|http://purl.oboli...|       1|\n",
      "|http://www.ebi.ac...|       4|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from graphframes import *\n",
    "g = GraphFrame(df_label, df_hier)\n",
    "g.inDegrees.show()\n",
    "# g = GraphFrame(vertex, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                from|                  e0|                  to|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[http://purl.obol...|[http://purl.obol...|[http://purl.obol...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iri= 'http://purl.obolibrary.org/obo/iao_0000030'\n",
    "# http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay\n",
    "# http://purl.obolibrary.org/obo/chebi_62943\n",
    "# http://purl.obolibrary.org/obo/chebi_133771\n",
    "# http://www.w3.org/2002/07/owl#thing\n",
    "paths = g.bfs(\"id = 'http://purl.obolibrary.org/obo/chebi_133771'\", \"id = 'http://purl.obolibrary.org/obo/chebi_62943'\")\n",
    "paths.show()\n",
    "\n",
    "# # Specify edge filters or max path lengths.\n",
    "# g.bfs(\"name = 'Esther'\", \"age < 32\",\\\n",
    "#   edgeFilter=\"relationship != 'friend'\", maxPathLength=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                  id|degree|\n",
      "+--------------------+------+\n",
      "|http://purl.oboli...|353299|\n",
      "|http://www.w3.org...| 37470|\n",
      "|http://purl.oboli...| 14253|\n",
      "|http://purl.oboli...|  7331|\n",
      "|http://purl.oboli...|  7230|\n",
      "|http://purl.oboli...|  4805|\n",
      "|http://purl.oboli...|  4107|\n",
      "|http://purl.oboli...|  3939|\n",
      "|http://purl.oboli...|  2824|\n",
      "|http://purl.oboli...|  2468|\n",
      "|http://purl.oboli...|  2030|\n",
      "|http://purl.oboli...|  1941|\n",
      "|http://purl.oboli...|  1930|\n",
      "|http://purl.oboli...|  1798|\n",
      "|http://purl.oboli...|  1684|\n",
      "|http://purl.oboli...|  1471|\n",
      "|http://www.cogpo....|  1468|\n",
      "|http://www.ebi.ac...|  1429|\n",
      "|http://www.geneon...|  1345|\n",
      "|http://purl.oboli...|  1182|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "degrees = g.degrees.sort(desc(\"degree\"))\n",
    "degrees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|               label|\n",
      "+--------------------+--------------------+\n",
      "|http://purl.oboli...|       dron 00060820|\n",
      "|http://purl.oboli...|       dron 00273407|\n",
      "|http://purl.oboli...|       dron 00116305|\n",
      "|http://purl.oboli...|       dron 00636386|\n",
      "|http://purl.oboli...|       dron 00641546|\n",
      "|http://purl.oboli...|       dron 00056018|\n",
      "|http://ncicb.nci....|benign sertoli ce...|\n",
      "|http://purl.oboli...|       dron 00176142|\n",
      "|http://www.orpha....|     orphanet 295024|\n",
      "|http://purl.oboli...|       dron 00067248|\n",
      "|http://purl.oboli...|       dron 00581219|\n",
      "|http://purl.oboli...|       dron 00678487|\n",
      "|http://purl.oboli...|       dron 00040995|\n",
      "|http://purl.oboli...|   desmosine residue|\n",
      "|http://purl.oboli...|       dron 00604278|\n",
      "|http://purl.oboli...|       dron 00043974|\n",
      "|http://ncicb.nci....|      barth syndrome|\n",
      "|http://purl.oboli...|       dron 00518678|\n",
      "|http://purl.oboli...|         chebi 18729|\n",
      "|http://www.bioass...|         bao 0002683|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|                 src|                 dst|\n",
      "+--------------------+--------------------+\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://www.ebi.ac...|http://www.ebi.ac...|\n",
      "|http://www.ebi.ac...|http://www.ebi.ac...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://www.semant...|http://www.semant...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://ncicb.nci....|http://ncicb.nci....|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "|http://purl.oboli...|http://purl.oboli...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the vertex and edge DataFrames\n",
    "g.vertices.show()\n",
    "# +--+-------+---+\n",
    "# |id|   name|age|\n",
    "# +--+-------+---+\n",
    "# | a|  Alice| 34|\n",
    "# | b|    Bob| 36|\n",
    "# | c|Charlie| 30|\n",
    "# | d|  David| 29|\n",
    "# | e| Esther| 32|\n",
    "# | f|  Fanny| 36|\n",
    "# | g|  Gabby| 60|\n",
    "# +--+-------+---+\n",
    "\n",
    "g.edges.show()\n",
    "# +---+---+------------+\n",
    "# |src|dst|relationship|\n",
    "# +---+---+------------+\n",
    "# |  a|  b|      friend|\n",
    "# |  b|  c|      follow|\n",
    "# |  c|  b|      follow|\n",
    "# |  f|  c|      follow|\n",
    "# |  e|  f|      follow|\n",
    "# |  e|  d|      friend|\n",
    "# |  d|  a|      friend|\n",
    "# |  a|  e|      friend|\n",
    "# +---+---+------------+\n",
    "\n",
    "# Get a DataFrame with columns \"id\" and \"inDegree\" (in-degree)\n",
    "vertexInDegrees = g.inDegrees\n",
    "\n",
    "# Find the youngest user's age in the graph.\n",
    "# This queries the vertex DataFrame.\n",
    "# g.vertices.groupBy().min(\"age\").show()\n",
    "\n",
    "# Count the number of \"follows\" in the graph.\n",
    "# This queries the edge DataFrame.\n",
    "# numFollows = g.edges.filter(\"relationship = 'follow'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "condition should be string or Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3455abc9b616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miri2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_hier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miri2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_hier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# def findChildrenDF(iri):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     return df_hier.filter(lambda x: x[0] == iri)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"condition should be string or Column\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: condition should be string or Column"
     ]
    }
   ],
   "source": [
    "iri2 = 'http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay'\n",
    "df_hier.filter(lambda x: x[0] == iri2).take(2)\n",
    "df_hier.filter(lambda x: x[0] == iri).take(2)\n",
    "# def findChildrenDF(iri):\n",
    "#     return df_hier.filter(lambda x: x[0] == iri)\n",
    "\n",
    "# df = sc.parallelize(iri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllChildren(iri, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "    result = []\n",
    "    pair = []\n",
    "    for child_iri in getChildrenFast(iri) - visited:\n",
    "        print(\"get child: \", child_iri)\n",
    "        if child_iri:\n",
    "            result.append(child_iri)\n",
    "            pair.append((child_iri, iri))\n",
    "            result1, pair1 = getAllChildren(child_iri, visited)\n",
    "            result += result1\n",
    "            pair += pair1\n",
    "            visited.add(child_iri)\n",
    "            \n",
    "    return result, pair\n",
    "\n",
    "iri= 'http://purl.obolibrary.org/obo/chebi_62943'\n",
    "test = IRIRelatedTables(iri)\n",
    "c_vertices, c_edges = getAllChildren(iri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_labels.createOrReplaceTempView(\"class_labels\")\n",
    "\n",
    "iri = \"http://purl.obolibrary.org/obo/iao_0000030\"\n",
    "print(spark.sql(\"SELECT * from class_labels where CLASS_IRI = '\" + iri +\"'\").collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL=df_class_hier.join(df_class_labels, 'CLASS_IRI').select(df_class_hier.CLASS_IRI, df_class_labels.CLASS_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.count()\n",
    "df_IRI_LABEL.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.groupBy(\"CLASS_IRI\").count().sort(\"count\", ascending=False).limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IRI_LABEL.show(10,truncate= True)\n",
    "result = df_IRI_LABEL.where(df_IRI_LABEL.CLASS_IRI == 'http://purl.obolibrary.org/obo/iao_0000030').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.count())\n",
    "result.collect()[1]['CLASS_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result.collect():\n",
    "    print(row['CLASS_IRI'], row['CLASS_LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def isIRIEqualLabel(iri, label):\n",
    "    iri = iri.split('/')[-1].replace('_',' ')\n",
    "    return label ==iri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in result.collect():\n",
    "    if not isIRIEqualLabel(row[0], row[1]):\n",
    "        print(row[0], row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIRI(label):\n",
    "    result = []\n",
    "    iris = df_class_labels.filter(df_class_labels.CLASS_LABEL==label).select('CLASS_IRI','CLASS_LABEL').distinct().collect()\n",
    "    for row in iris:\n",
    "        if not isIRIEqualLabel(row[\"CLASS_IRI\"], row['CLASS_LABEL']):\n",
    "            result.append(row[\"CLASS_IRI\"])\n",
    "    return result\n",
    "\n",
    "def getLabel(iri):\n",
    "    result =[]\n",
    "    labels = df_class_labels.filter(df_class_labels.CLASS_IRI==iri).select('CLASS_IRI','CLASS_LABEL').distinct().collect()\n",
    "    for row in labels:\n",
    "        if not isIRIEqualLabel(row[\"CLASS_IRI\"], row['CLASS_LABEL']):\n",
    "            result.append(row[\"CLASS_LABEL\"])\n",
    "    return result\n",
    "\n",
    "def getOnts(iri):\n",
    "    result =[]\n",
    "    ont_names = df_class_labels.filter(df_class_labels.CLASS_IRI==iri).select('ONT_NAME').distinct().collect()\n",
    "    for row in ont_names:\n",
    "        result.append(row[\"ONT_NAME\"])\n",
    "    return result\n",
    "            \n",
    "\n",
    "def getParents(iri):\n",
    "    result =set()\n",
    "    if iri == 'http://www.w3.org/2002/07/owl#thing':\n",
    "        return result\n",
    "    print(\"get parent for: \", iri) \n",
    "    parents = df_class_hier.filter(df_class_hier.CLASS_IRI==iri).distinct().collect()\n",
    "    for row in parents:\n",
    "        result.add(row['PARENT_CLASS_IRI'])\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def getChildren(iri):\n",
    "    result =set()\n",
    "    children = df_class_hier.filter(df_class_hier.PARENT_CLASS_IRI==iri).distinct().collect()\n",
    "    for row in children:\n",
    "        result.add(row['CLASS_IRI'])\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def getArea(iri, tax_type = 'op_restriction'):\n",
    "    result = df_tax_areas_concepts.filter((df_tax_areas_concepts.TAX_TYPE==tax_type)&\\\n",
    "                                          (df_tax_areas_concepts.CLASS_IRI==iri) & \\\n",
    "                                          (df_tax_areas_concepts.AREA_ID!='[empty set]'))\\\n",
    "    .join(df_tax_areas,'AREA_ID').drop(df_tax_areas.TAX_TYPE)\n",
    "    area = result.select('TAX_TYPE','AREA_ID', 'AREA_NAME', 'AREA_LEVEL').collect()\n",
    "#     area = result.collect()\n",
    "    return area\n",
    "\n",
    "def getOntName(iri):\n",
    "    return ont\n",
    "\n",
    "def getPArea(iri, tax_type = 'op_restriction'):\n",
    "    result = df_tax_areas_pareas.filter((df_tax_areas_pareas.TAX_TYPE==tax_type)&\\\n",
    "                                        (df_tax_areas_pareas.CLASS_IRI==iri) & \\\n",
    "                                          (df_tax_areas_pareas.PAREA_ROOT_IRI!='[empty set]'))\n",
    "    parea = result.drop('ONT_NAME').distinct().collect()\n",
    "    return parea\n",
    "\n",
    "def getAreaLevel(iri, tax_type = 'op_restriction'):\n",
    "    df_tax_areas_concepts2=df_tax_areas_concepts.filter((df_tax_areas_concepts.TAX_TYPE==tax_type)&\\\n",
    "                                                        (df_tax_areas_concepts.CLASS_IRI == iri)& \\\n",
    "                                                          (df_tax_areas_concepts.AREA_ID!='[empty set]'))\n",
    "    \n",
    "    result = df_tax_areas.join(df_tax_areas_concepts2, 'AREA_ID').drop('ONT_NAME').distinct().first()\n",
    "    \n",
    "    if not result:\n",
    "        return 0\n",
    "    else:\n",
    "        return result['AREA_LEVEL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAreaLevel(\"http://purl.obolibrary.org/obo/apollo_sv_00000144\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getIRI(\"information content entity\"))\n",
    "print(getLabel(\"http://purl.obolibrary.org/obo/iao_0000030\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getArea('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "getChildren('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "# result = df_tax_areas_concepts.filter(df_tax_areas_concepts.CLASS_IRI=='http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')\n",
    "\n",
    "# result.filter(df_tax_areas_concepts.AREA_ID!='[empty set]').show()\n",
    "getParents('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPArea('http://chem2bio2rdf.org/chem2bio2rdf.owl#bioassay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_hier\n",
    "df_class_labels\n",
    "df_tax_areas\n",
    "df_tax_areas_concepts\n",
    "df_tax_areas_pareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getPArea('http://www.w3.org/2002/07/owl#thing')\n",
    "getParents('http://www.w3.org/2002/07/owl#thing')\n",
    "getParents('http://www.ifomis.org/bfo/1.1#entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPAreaParent(iri, depth=1):\n",
    "    result = []\n",
    "    for i in range(depth):\n",
    "        for row in getPArea(iri):\n",
    "            result.append((iri, row['PAREA_ROOT_IRI']))\n",
    "            result + getPAreaParent(getParents(row['PAREA_ROOT_IRI']))\n",
    "            \n",
    "def getAreaParent(iri, depth):\n",
    "    parents= []\n",
    "\n",
    "    \n",
    "    \n",
    "def getPAreaChildren(iri, depth=1):\n",
    "    result = []\n",
    "    for i in range(depth):\n",
    "        for row in getPArea(iri):\n",
    "            result.append((row['PAREA_ROOT_IRI'], iri))\n",
    "            result + getPAreaChilren(getChildren(row['PAREA_ROOT_IRI']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllChildren(iri, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "    result = []\n",
    "    pair = []\n",
    "    for child_iri in getChildren(iri) - visited:\n",
    "        print(\"get child: \",child_iri)\n",
    "        if child_iri:\n",
    "            result.append(child_iri)\n",
    "            pair.append((child_iri, iri))\n",
    "            result1, pair1 = getAllChildren(child_iri, visited)\n",
    "            result += result1\n",
    "            pair += pair1\n",
    "            visited.add(child_iri)\n",
    "            \n",
    "    return result, pair\n",
    "c_vertices, c_edges = getAllChildren('http://purl.obolibrary.org/obo/chebi_62943')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParents(iri, visited = None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "    visited.add(iri)\n",
    "\n",
    "    result = []\n",
    "    pair = []\n",
    "    if iri != 'http://www.w3.org/2002/07/owl#thing':\n",
    "        for parent_iri in getParents(iri) - visited:\n",
    "            print(\"get parent: \", parent_iri)\n",
    "            if parent_iri:\n",
    "                result.append(parent_iri)\n",
    "                pair.append((iri, parent_iri))\n",
    "                result1, pair1 = getAllParents(parent_iri, visited)\n",
    "                result += result1\n",
    "                pair += pair1\n",
    "                visited.add(parent_iri)\n",
    "    return result, pair\n",
    "\n",
    "p_vertices, p_edges = getAllParents('http://purl.obolibrary.org/obo/chebi_62943')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "g = ig.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_vertex(name = 'http://purl.obolibrary.org/obo/chebi_62943')\n",
    "g.add_vertices(p_vertices)\n",
    "\n",
    "# for vertex in vertices:\n",
    "#     g.add_vertex(name=vertex)\n",
    "\n",
    "N=g.vcount()\n",
    "print('total number of vertices imported: ' , N)\n",
    "print(p_edges)\n",
    "\n",
    "g.add_edges(p_edges)\n",
    "\n",
    "L= g.ecount()\n",
    "print('added # of edges: ', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.add_vertex(name = 'http://purl.obolibrary.org/obo/chebi_62943')\n",
    "g.add_vertices(c_vertices)\n",
    "\n",
    "# for vertex in vertices:\n",
    "#     g.add_vertex(name=vertex)\n",
    "\n",
    "N=g.vcount()\n",
    "print('total number of vertices imported: ' , N)\n",
    "print(c_edges)\n",
    "\n",
    "g.add_edges(c_edges)\n",
    "\n",
    "L= g.ecount()\n",
    "print('added # of edges: ', L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "group=[]\n",
    "for node in g.vs:\n",
    "    labels.append(getLabel(node['name']))\n",
    "    group.append(getAreaLevel(node['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in g.vs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layt=g.layout_auto(dim=3)\n",
    "layt[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn=[layt[k][0] for k in range(N)]# x-coordinates of nodes\n",
    "Yn=[layt[k][1] for k in range(N)]# y-coordinates\n",
    "Zn=[layt[k][2] for k in range(N)]# z-coordinates\n",
    "Xe=[]\n",
    "Ye=[]\n",
    "Ze=[]\n",
    "for e in g.es:\n",
    "    e=e.tuple\n",
    "    Xe+=[layt[e[0]][0],layt[e[1]][0], None]# x-coordinates of edge ends\n",
    "    Ye+=[layt[e[0]][1],layt[e[1]][1], None]\n",
    "    Ze+=[layt[e[0]][2],layt[e[1]][2], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1=Scatter3d(x=Xe,\n",
    "               y=Ye,\n",
    "               z=Ze,\n",
    "               mode='lines',\n",
    "               line=Line(color='rgb(125,125,125)', width=1),\n",
    "               hoverinfo='none'\n",
    "               )\n",
    "trace2=Scatter3d(x=Xn,\n",
    "               y=Yn,\n",
    "               z=Zn,\n",
    "               mode='markers',\n",
    "               name='actors',\n",
    "               marker=Marker(symbol='dot',\n",
    "                             size=6,\n",
    "                             color=group,\n",
    "                             colorscale='Viridis',\n",
    "                             line=Line(color='rgb(50,50,50)', width=0.5)\n",
    "                             ),\n",
    "               text=labels,\n",
    "               hoverinfo='text'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis=dict(showbackground=False,\n",
    "          showline=False,\n",
    "          zeroline=False,\n",
    "          showgrid=False,\n",
    "          showticklabels=False,\n",
    "          title=''\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = Layout(\n",
    "         title=\"Network of coappearances of characters in Victor Hugo's novel<br> Les Miserables (3D visualization)\",\n",
    "         width=1000,\n",
    "         height=1000,\n",
    "         showlegend=False,\n",
    "         scene=Scene(\n",
    "         xaxis=XAxis(axis),\n",
    "         yaxis=YAxis(axis),\n",
    "         zaxis=ZAxis(axis),\n",
    "        ),\n",
    "     margin=Margin(\n",
    "        t=100\n",
    "    ),\n",
    "    hovermode='closest',\n",
    "    annotations=Annotations([\n",
    "           Annotation(\n",
    "           showarrow=False,\n",
    "            text=\"Data source: <a href='http://bost.ocks.org/mike/miserables/miserables.json'>[1] miserables.json</a>\",\n",
    "            xref='paper',\n",
    "            yref='paper',\n",
    "            x=0,\n",
    "            y=0.1,\n",
    "            xanchor='left',\n",
    "            yanchor='bottom',\n",
    "            font=Font(\n",
    "            size=14\n",
    "            )\n",
    "            )\n",
    "        ]),    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Data([trace1, trace2])\n",
    "fig=Figure(data=data, layout=layout)\n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "py.offline.iplot(fig, filename='Les-Miserables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
